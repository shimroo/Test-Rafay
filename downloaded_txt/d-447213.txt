




thinking for a change







































thinking for a changetreppenwitz in publiccommentsposts













 nayima
  
about

categories 
agile

agile analysis

agile2008

agile2009

agilenorth

agileopen

books

events

games

lean

music

presentations

real options

simblogging

spa2006

spa2008

systems thinking

theory of constraints

toyota way

uncategorized

xp days benelux

xpday


blogroll

emmanuel gaillot
eugene wallingford
gino marckx
glen alleman
laurent bossavit
marc evers
portia tung
presentation zen
zenika







dec27 
we’re off on an adventure!			 


the dream team nightmare
it took a while to arrive because the book was out of stock at amazon, but it’s finally here, just in time for the holiday break: portia tung‘s “dream team nightmare“!
i sat down with a cup of coffee and started to read the book. portia’s writing style is engaging and lively with lots of dialogue and very short chapters. at the bottom of the chapters you have to make a choice and then go to a designated page.
i’ve been on agile projects for years, so i expected to breeze through the book. after all, most teams face the same problems. i’ve solved them many times. why should this “dream team” be any different?
after only a few pages i read
patrick [who hired you as an agile coach] asks his secretary to escort you out of the office. before you know it, you’re back on the street.
it feels like you’ve been punched in the gut. thoughts swirl in your head. should have. would have. could have. you decide to take time out to reflect on what happened. you’re not quite ready to give up doing a job you love. not yet.
the end
fired! on my first day. game over. do you want to play again? of course, but now i’ll make smarter choices.
and… i was asked to leave the dream team and see if things would go better with another team. the end.
“if at first you don’t succeed, stubbornly try again and again”, that’s my motto. so, one more try.
aha! we come to a part where my mission is described as a user story with acceptance tests. that will help me to understand better what’s expected. i restart the book and start working with the team. i flip backwards and forwards as the book directs me to see the consequences of my choices. it’s getting smoother. and then there’s a conflict with one of the team members. at the end of the 5 days i present my recommendations. and then… nothing happens. the end.
this agile coaching lark is harder than it looks.
this is frustrating. i’ve only scratched the surface of the book, read a few chapters and each time i reach a dead end. reminds me of some projects i’ve been on.
and then i have a brilliant idea.
what would portia do?
i’ve been lucky to work with portia and see her at work. i will restart the last time and at each choice ask myself “what would portia have done in this situation?” portia would

talk to everybody to understand what motivates them
help the team to make their own decisions
reach agreement on the value we’re creating
get a good understanding of where we are
define goals together and clarify them with testable acceptance criteria
take some time to reflect regularly
help the team to create and explore options
lighten up the mood with silly exercises like “profile cards“, cookies and team lunches

i can do that. it’s just a matter of taking a bit more time before making a decision. let’s start again, from the top.
this time, with the help of portia (sometimes in the role of jiminy cricket to keep me on the straight and narrow, sometimes as the blue fairy who grants wishes and saves the day) i progress through the book. there are still a few choices, but fewer and fewer.
the team starts working together to visualize their situation. faced with the enormity of their task, they feel demoralized. we come up with three options to deliver value and involve the product owner.
and there it gets tricky. if i’m not careful, the unspoken simmering conflict between team and product owner/management erupts again: the company needs more than the team can deliver; the team blames the product owner for imposing unrealistic scope and deadline. the end.
and that’s where it usually ends, but there’s another option. there’s always another option.
instead of saying “it’s impossible to deliver this scope by this deadline!” you can ask “what do we need to achieve the goal before the deadline?” two other agile teams “predator” and “green” can help the dream team. the teams apply real options to decide on the day when they have to decide. meanwhile they create and explore more options to achieve the company’s goal: different ways to select scope and divide the work between the teams.
finally, a happy end
from there it’s relatively smooth sailing. by now i see the trap on page 216, where i fail to ask the team to review and improve my recommendations because i’m rushed, coming by a mile. if only it were this easy in real life to take a step back for a moment and take the time to think…
and then we arrive at the final chapters: the team present their delivery options and their improvement actions. everybody’s energized to work on those actions. i don’t know if they’ll live happily ever after, but the adventure continues.
the end
observations and recommendations

there’s a list of recommended tools on page 203. appendix 5 contains the coaching tools used in the book. it would be useful to have some links where i can find out more about each of the tools. maybe something for the agile adventure site?
i loved seeing the current and future reality trees in use. it would have been great to see a “conflict resolution diagram” be used to bridge the gap between root causes and improvement actions. what are the underlying conflicts that have led and kept the team in its unhappy situation? maybe something for the next agile adventure?
flipping back and forth between chapters isn’t always practical in a paper book. but you can have your cake and eat it too. i bought both the paper and e-book version: the e-book to play, the paper book to loan
there are a few illustrations in the book: current/future reality trees, profile cards. a few more illustrations would have made the story a bit more vivid: what does the kanban board look like? what does the team area look like? no need to make it into a graphic novel. henrik kniberg‘s “… from the trenches” books are a good example of how illustrations can make the story more vivid.

done. what’s left on the holiday reading backlog?
some more light reading, because i don’t want to be that agile coach who hasn’t written production code for a decade.
  
can anyone recommend a good e-book about clojure that covers core.async?

december 27th, 2013 |  category: agile, books 


jun04 
xp days benelux 2013 – call for session proposals			 

xp days benelux is an international conference where we learn to bring software to life and grow mature systems that support business needs.
it provides an excellent environment for exchanging ideas, hands-on exercises and extreme experiences.
the best way to learn is to facilitate a session. we like sessions where you explore ideas as well as questions.
the conference will be held on 28 and 29 november, 2013 in mechelen, belgium.
the best way to learn is to facilitate a session at xp days!
we’re looking for sessions where you explore ideas as well as questions. sessions that dig deeper, going beyond the basic techniques and practices. we really want to find out why/how things work or don’t work. we invite you to propose:

hands on coding/design/architecture sessions;
discovery sessions – open ended workshops that explore new topics, common problems, promising techniques, or burning questions;
experiential learning sessions; get people learning by doing & reflecting; for example games or simulations.

we’re not only interested in agile and software related topics but we also want to explore boundaries and cross borders. what can we learn from other disciplines or sciences?
available timeslots are 75 and 150 minutes.
we also welcome short experience reports (30 minutes) that focus on what didn’t work and why.
do you have an interesting story, idea or question?
send us your session idea today.
what’s so special about xp days?
for one thing, we constantly try to apply xp, agile, lean, systems thinking, theory of constraints and all the other stuff we talk about. it wouldn’t be an agile conference if it wasn’t organised by using agile values, principles and techniques.
for example: how is the way we build the program agile?
collaborating to get the best possible sessions
we don’t think bduf is appropriate or possible, not even for a session description. therefore, we ask session authors to send in a simple proposal: title, subtitle, presenters, description. it’s the equivalent of a story card: the promise for a conversation about the session.
once the proposal is sent in, the author(s) can incrementally fill in more information, as the session becomes clearer. there’s a separate deadline for submitting proposals (july 13th) and finalising the proposals (august 28th), to avoid “student syndrome” and last-minute session hurried submissions. within those two timeboxes, the authors work at their own (sustainable) pace.
session authors help other session authors by asking questions and giving feedback using the “perfection game“. the proposal authors (and the conference organisers) act as “peer coaches“. through the magic of questions and feedback, the proposal author iteratively improves their proposal(s). aren’t session authors helping their “competitors” in the race for a place in the program? we typically get 3 proposals per slot, so the competition is fierce. well, nobody said collaboration was easy. in the end we all benefit from a better conference program. and the organisers see who applies the agile values and who just talks about them.
isn’t this coaching only useful for beginners? it certainly helps new presenters to marshal their ideas. but, as we’ve experienced while pair programming, experienced presenters get new insights and clarity when “juniors” ask naive questions.

the most powerful coaching questions focus on goals and benefits for participants. why should someone come to this sessions? what is the one idea you want to get across? what will participants be able to do after attending this session that they couldn’t do before? how will you know this session was a success for participants?
a common problem with session proposals is that the authors try to “pile on” too many ideas. the usual session feedback reads “not enough time”. the solution is not to take more time, but to present less material more thoroughly. think deeply: what is your minimum viable product? if there’s any time left in your session you can spend it on interaction with participants and exploration of your central idea, rather than adding more ideas.
release early, release often
a session proposal is not a session. you may have created the greatest session proposal, that doesn’t mean you’ve got the greatest session. there’s only one way to know if your session design works: implement it, release it and get feedback from participants. we therefore encourage presenters to do “tryouts” of their session. we offer places to do this at the agile belgium and agile holland meetups. you may be able to schedule a tryout at a local user group or in your company. or just invite a few friends and colleagues to try out your session.
seasoned presenters know that it takes at least three iterations to get all the details and the timing right.
preparing to select sessions
now that we’ve iteratively improved session descriptions, the most difficult task is to select the sessions for the program.
near the end of the session improvement process we ask all session authors to select the sessions they want to see in their “ideal track”. we use these votes as a start of our selection process.
we also use these votes to calculate the “value” of a draft program. we do this by calculating the program attendance factor (paf) for each voter. the paf value indicates how many of their preferred sessions a voter can attend, given the layout of the program. to count, a preferred session must be in the program and it must not be at the same time as another preferred session. a program that has a higher total paf has more value for voters, because they can attend more preferred sessions.
in preparation for the program committee meeting we create a card for each session. making a conference program requires a lot of visual management:

the color of the card indicates the type of subject so that we can quickly see if the program has a good balance of sessions
the names of the presenters are clear so that we can ensure no presenter has more than one session in a day (sustainable presenter pace)
the card has coloured dots to indicate the type of session and the experience level so that we can see at a glance if there’s a good balance for participants with different learning styles and experience
the cards have different sizes representing session length so that we can’t put them in program slots of the wrong size

the program committee reviews all session proposals before the program committee meeting. there are so many proposals that program committee members can’t review or even read them all. therefore, the committee divides the sessions among its members and trusts that the other members have good judgment.
before the program committee meeting, the proposals are put into four categories:

the sessions we really want to see in the program. each program committee member can “champion” a session
the sessions that we won’t consider because they’re incomplete, withdrawn or inappropriate
the sessions that were selected in the voting process
other sessions

sessions on the board
we have large sheets of paper that represent each of the days with drawn slots that are just the right size for the session cards.

building a program happens in three rounds:

create a first version by putting the championed and most voted for sessions in appropriate slots. we do this track per track. for example: first fill a track on both days with technical sessions, then fill a track with process sessions… it’s ok if some slots are still empty.this first step should go quite quickly, without too much discussion. the goal is not to create a perfect program; it’s not even a workable program. we just need a version to start iterating.
we spot a constraint violation, for example. a presenter who does two sessions in one day or we’ve selectedtoo many sessions of one type or subject. we resolve the constraint by swapping the problem session with another same-sized session already on the board or not on the board. we may also spot improvements in balance or paf score. these are also performed using swaps. the only constraint is that we can’t introduce constraint violations by this swap. we keep iterating until the program stabilizes. we select a few “backup” sessions that we can add to the program in case one of the selected presenters can’t come.
we internally publish a draft version of the program. all organizers can review the program at their leisure to spot any constraint violations or improvements. we often have to take a bit of distance to spot these. when nobody has any more improvement ideas, we contact the authors of selected and rejected proposals. sometimes presenter availability can introduce new constraints (for example, the presenter can only be present on the first day but his session is scheduled on the second day). in that case, we go back to swapping sessions to resolve the constraint.
done. until something happens like a presenter dropping out.

getting better

we continuously improve this session proposal-improvement-review-selection process. we’ve incrementally built a tool that supports our workflow. new features get added just-in-time as we notice irritations or get new ideas for improvement. most of the organisers participate in other conferences where we “‘steal” the best ideas. in return, we invite everybody to “steal” any idea they like.
in summary: creating a proposal, growing and refining it, coaching other to improve their proposal, doing tryouts and refining the session is a lot of work. and then you might not even get selected because there are so many great proposals.
is it worth it? what’s the worst thing that could happen? you spent some time to understand an interesting subject better. that’s not so bad, is it? if you get selected or if you just attend, you get to spend two days with open, intelligent, helpful and experience people to explore and discover interesting new ideas and problems. and one of those ideas or problems could be yours.

june 4th, 2013 |  category: agile, events, xp days benelux, xpday 


may30 
ignore the cost accountants at your peril, because they won’t ignore you			 

why should i learn about cost accounting?
it may not be immediately obvious, but the way your company manages its finances, costs and budgets has a profound effect on the way projects or products are started, run and terminated. you may have been in situations where you sat back in amazement at some incomprehensible management decision and thought “what were they thinking?”
they were probably thinking about budgets and costs. you will be surprised again next time unless you learn to understand and dialogue with your cfo and cost accountants.
fun with cost accounting
pierre hervouet and i have created a session that explains the basics of cost accounting (based on making and pricing cocktails) and presents three alternative views you may find useful:

throughput accounting
lean accounting
beyond budgeting

the session doesn’t certify you as an accounting master, but it provides food for thought and pointers to plenty of material you can dig into if you want to know more. the materials (currently only in french) are published on the agilecoach site.
join the conversation
why don’t you go see your cfo or cost accountants today? ask them what’s keeping them up at night. you may discover that you face much the same issues and that the solutions are similar. yes, yes, accounting and budgeting are getting more agile, more lean!
the agile alliance has a new “agile accounting standards” program to “engage with fasb’s emerging issues task force to promote and develop an agile accounting standard that will better define and standardize internal it development costs for organizations that use an iterative or agile software development methodology” because  “the phased gate language [of the current standard] results in significant confusion and challenges of interpreting how to map the iterative work that happens throughout an agile project lifecycle and is becoming an increasing urgent issue.“

may 30th, 2013 |  category: agile, lean, presentations, systems thinking, theory of constraints 


apr03 
a simple property dialog – an alternative approach			 

performing a root cause analysis for a simple bug takes too much time
in a previous post i described how we performed a root cause analysis for a simple bug: one incorrect value  in a dropdown. performing such a heavy analysis (which generates a lot of rework) may not be appropriate for every bug.
here’s how another team handled a very similar bug: one value missing from a dropdown.
the fast way to deal with simple bugs

there’s a bug: in one screen one of the dropdowns misses one value: “x”. this bug is unexpected: in all other screens the behaviour of the dropdowns is correct, each of them contains “x” as the final and default value. this bug only appears in one screen. why only this screen? what’s so special about this screen? isn’t this the same code for all dropdowns with the same behaviour?
the bug is reported during internal testing. the bug can be repeated very easily.
developers grumble (i told you the “thank you” step in the  algorithm to write perfect code was difficult!)
a developer takes the bug and fixes it: an extra value “x” is added to the dropdown in the screen
tester validates: go into the screen; open the dropdown; the value “x” is there. bug closed.
software gets shipped to customer
done. next bug!

easy.
a few days later…

customer files a bug report: each time they enter this specific screen an “x” gets added to the dropdown. enter the screen twice, you see “x” “x”. enter again, you see “x” “x” “x”. and so on…
developers grumble: “not another stupid bugreport!“
a developer takes the bug and analyses it. “some idiot has added ‘x’ to this dropdown. let’s remove that.“
tester validates: go into the screen; open the dropdown; no “x” is added. bug closed.
software gets shipped to customer
done. next bug!

easy. only took a few minutes to fix and (a few days later) a few minutes to test. and another release to build, ship and install.
a few days later…

customer reopens their bug report: when they enter the screen, there is no “x”. to be clear: they expect exactly one “x” in this dropdown (and all similar dropdowns in other screens). not zero. not an infinite number.
developers grumble. “when will they make up their mind?“
developer takes the bug and fixes it: an “x” is added to the dropdown unless there’s already an “x” in the dropdown
tester validates: go into the screen, one “x”; go into the screen again, still one “x”; go into the screen again, still one “x”; go into other screens; go into this screen, still one “x”. stop the application. restart the application. go into the screen, one “x”; go into the screen again, still one “x”. bug closed.
software gets shipped to customer
done

easy. only took an hour or two to fix and (a few days later) an hour to test. and another release to build, ship and install.
and they all lived happily ever after
except for the customer who grumbles “how can i trust them with the important stuff if they can’t get the simple stuff right?”
except for the developers who grumble “how can we get any work done if we have to keep fixing these stupid bugs?”
except for the testers who grumble “why do we have to retest every bugfix a thousand times? can’t ‘they’ get things right the first time? we need fewer releases, more detailed specs, more elaborate test scripts, more time to test and, above all, a lot more testers to get any quality in this application.“

april 3rd, 2013 |  category: agile, systems thinking 


apr02 
a simple property dialog – adventures in root cause analysis			 

i’ve been going on a bit lately about the value i get from of performing “root cause analysis” when i encounter a bug.

 great! another bug  from agilecoach.net
a simple algorithm to write perfect code
you don’t have to watch the presentation. the message is this: each time there’s a bug:

someone finds a problem and reports it to you
thank the reporter
reproduce the problem
add (at least) one failing test
correct the problem
rerun all tests and correct your correction until the tests pass
improve your tests
improve the way you write tests
look for similar problems. goto 2
make this type of problem impossible
perform the actions that were identified during the root cause analysis

 but that’s just common sense!
we’re all agile lean continuously improving test driven extreme programmers, aren’t we? doesn’t everybody do this?
yes… but…

it takes too much time
we can’t do this for every bug because we’ve got too many bugs
we don’t want to waste time on bugs, we prefer to spend time adding valuable features
as dijkstra said: “ program testing can be a very effective way to show the presence of bugs, but it is hopelessly inadequate for showing their absence.”
<your objection here>

just a little taste
the presentation tells the story of a team that performed a root cause analysis. here’s another team’s story:
coach: can we try a small root cause analysis experiment?
dev: yes, but… we don’t have a lot of time.
coach: do you have one hour? we can timebox the experiment.
dev: sure, but… you can’t do anything useful in one hour.
coach: maybe you can’t; maybe we can.
dev: ???
coach: have you seen any interesting bugs lately?
dev: well, i just fixed a bug. but it’s so trivial you won’t discover anything useful.
coach: thank you! let’s see.
i love clear bug reports
first we look at the bug report:





given a swizzled foobar (*)

when i change its properties

then i expect to be offered a choice between 'a', 'b' or 'z' for the status

but i'm offered 'a', 'b' or 'c'

(*) all names of domain objects have been changed to protect the innocent and the guilty




123456789

given a swizzled foobar (*) when i change its properties then i expect to be offered a choice between 'a', 'b' or 'z' for the status but i'm offered 'a', 'b' or 'c' (*) all names of domain objects have been changed to protect the innocent and the guilty






 let’s apply the algorithm
coach: have you thanked the reporter yet?
dev: no…
coach: let’s do it now.
dev: ok… <calls product manager>
dev: hi, i just called to thank you for reporting the bug about the property dialog of the swizzled foobar.
product manager: <surprised> ok…
dev: the report was so clear the bugfix almost wrote itself. thanks!
product manager: you’re welcome!
coach: ok. we’ve now done the hardest part; let’s do the next steps.
next step: reproduce the problem. that’s quite easy: start up the application, select a foobar, swizzle it and open its property dialog. look at the dropdown control for the status: it presents options ‘a’, ‘b’ and ‘c’.
coach: we have a manual test procedure. can we automate this test?
dev: no. this is user-interface code. we’ve performed some experiments earlier and decided that it wasn’t worth the time and effort to create and maintain automated tests for the user interface.
coach: ok.
fix and test
the fix was really simple
buggy :





 status.add('c') ;




1

 status.add('c') ;





fixed :





 if (foobar.swizzled()) {
   status.add('z') ;
 } else {
   status.add('c') ;
 }




12345

 if (foobar.swizzled()) {   status.add('z') ; } else {   status.add('c') ; }





rerun the application, perform the manual test: the correct options are now offered.
result! bug fixed! high five! job well done.

hmmmm… the fix is indeed simple and the bug is now gone. but that if is worrying. i’ve seen (and had to maintain) code that was riddled with ifs: each time a bug was detected, the developers added an if for the specific conditions and expected outcomes described in the bugreport. let’s add a post-rca action: let’s read and discuss the anti-if campaign.
dev: you see now: this is a trivial bugfix, there’s nothing to learn here.
coach:maybe. we’ve only spent 10 minutes yet. let’s see the rest of this code
show me the code
if i take off my glasses, squint a bit and look at the code, this is what i see:





void showproperties(foobar foobar) {




1

void showproperties(foobar foobar) {











}




1

}





red lines are user interface code, calls to the ui toolkit. green lines are simple java, c#, ruby… ui-independent code.
guess where the bug is… in the green code. but we can’t test it, because we can’t test user interface code. so, that doesn’t help us.
a small step for a programmer…
we don’t have any tests, so any refactoring is going to be risky. let’s do some simple, safe refactoring: let’s move all the green and red code together.
now the code looks something like this:





void showproperties(foobar foobar) {




1

void showproperties(foobar foobar) {











}




1

}





exactly the same code, it does exactly the same thing. what have we achieved? nothing. yet.
another small step
now that we’ve got all the green code together, what does it do? essentially, it fills in a number of variables (like the list of values for the status), which are filled up with values to put into the ui controls.
let’s do another small, safe refactor:

create a new class. i don’t have a good name yet, let’s call it “stuff” for the moment
move every local variable in the green code into the stuff class
create an instance of stuff in the function
fill in all fields of the instance, just like you fill in the local variables

again, nothing really changes. we’ve just collected all local variables in one object.
our code now looks something like this.





void showproperties(foobar foobar) {
 // green
 stuff stuff = new stuff() ;
 stuff.status.add('a') ;
 stuff.status.add('b') ;
 if (foobar.swizzled()) {
   stuff.status.add('z') ;
 } else {
   stuff.status.add('c') ;
 }
....
 // red
 statusdropdown.setoptions(stuff.status) ;
}




1234567891011121314

void showproperties(foobar foobar) { // green stuff stuff = new stuff() ; stuff.status.add('a') ; stuff.status.add('b') ; if (foobar.swizzled()) {   stuff.status.add('z') ; } else {   stuff.status.add('c') ; }.... // red statusdropdown.setoptions(stuff.status) ;}






finally, a real refactoring
now the code has been reorganised, we can finally do a real refactoring, still taking small steps because we’re working without a safety net.
let’s extract the green and red code in separate methods. our code now looks like this:





void showproperties(foobar foobar) {
 // green
 stuff stuff = prepare(foobar) ; // todo: find a better name
 // red
 display(stuff) ;
}




123456

void showproperties(foobar foobar) { // green stuff stuff = prepare(foobar) ; // todo: find a better name // red display(stuff) ;}





note to self: “stuff” and “prepare” aren’t very descriptive. that’s probably because we don’t understand the code well enough yet. let’s revisit naming when we understand better.
we’re now 30 minutes into the root cause analysis
a giant leap for testing
aha! we now have a method “prepare” which contains the bug and doesn’t depend on the ui. can we test the code now? yes we can!





void swizzledfoobarshavezstatus() {
 // given a swizzled foobar
 foobar foobar = makeafoobarsomehow() ;
 foobar.swizzle() ;

 // when i change its properties
 stuff stuff = foobarpropertydialog.prepare(foobar) ;

 // then i expect to be offered a choice between 'a', 'b' or 'z' for the status
 assertequals(3,stuff.status.getsize()) ;
 assertequals('a',stuff.status.get(0)) ;
 assertequals('b',stuff.status.get(1)) ;
 assertequals('z',stuff.status.get(2)) ;
}




1234567891011121314

void swizzledfoobarshavezstatus() { // given a swizzled foobar foobar foobar = makeafoobarsomehow() ; foobar.swizzle() ;  // when i change its properties stuff stuff = foobarpropertydialog.prepare(foobar) ;  // then i expect to be offered a choice between 'a', 'b' or 'z' for the status assertequals(3,stuff.status.getsize()) ; assertequals('a',stuff.status.get(0)) ; assertequals('b',stuff.status.get(1)) ; assertequals('z',stuff.status.get(2)) ;}





this test fails before the fix. it succeeds after the fix. we now have an automated regression test for this bug.
improve your tests
this test raises a lot of questions:

what if the foobar isn’t swizzled? are the options ‘a’, ‘b’ and ‘c’ correct in this case? should we add a test?
are there any other special cases for status depending on the properties of a foobar?
are there any other fields that depend on the properties of the foobar?
are there any other properties of the domain that are important?
….

this could be the start of a really great conversation with the product manager and testers!
result: we’re 45 min into the rca and we’ve written an automated regression test of that bug in supposedly untestable code.
names
those stupid names “stuff” and “prepare” irritate me. now that we’ve got automated tests for this code, we can refactor more audaciously.
what is “stuff”? it contains the data as its shown in the view of the foobar property dialog. it’s a viewmodel. let’s rename it to foobarproperties.
what does “prepare” do? it creates a foobarproperties and stuffs values into it. what does foobarproperties do? nothing, it just sits there and contains these values. we might as well move the code from prepare into foobarproperties:





void showproperties(foobar foobar) {
  foobarproperties properties = new foobarproperties(foobar) ;
  display(properties) ;
}




1234

void showproperties(foobar foobar) {  foobarproperties properties = new foobarproperties(foobar) ;  display(properties) ;}





and now the unit test becomes a unit test of foobarproperties, a pure processing class, no longer of the mixed processing/ui class foobarpropertydialog:





void swizzledfoobarshavezstatus() {
 // given a swizzled foobar
 foobar foobar = makeafoobarsomehow() ;
 foobar.swizzle() ;

 // when i change its properties
 foobarproperties properties = new foobarproperties(foobar) ;

 // then i expect to be offered a choice between 'a', 'b' or 'z' for the status
 assertequals(3,properties.status.getsize()) ;
 assertequals('a',properties.status.get(0)) ;
 assertequals('b',properties.status.get(1)) ;
 assertequals('z',properties.status.get(2)) ;
}




1234567891011121314

void swizzledfoobarshavezstatus() { // given a swizzled foobar foobar foobar = makeafoobarsomehow() ; foobar.swizzle() ;  // when i change its properties foobarproperties properties = new foobarproperties(foobar) ;  // then i expect to be offered a choice between 'a', 'b' or 'z' for the status assertequals(3,properties.status.getsize()) ; assertequals('a',properties.status.get(0)) ; assertequals('b',properties.status.get(1)) ; assertequals('z',properties.status.get(2)) ;}






improve the way you test
now that we have a unit test for foobarproperties we can add more tests for different cases. looking at those tests we’ll see that some properties of a foobar are independent of its state. e.g. we always have a status ‘a’ and ‘b’. we can include those invariants in our tests. we’ll talk with the product manager first and together extend the testcase.
we can now see that we consider too much code as “ui code” and therefore not testable. if we separate viewmodel code from view code, we can cover more code with fast unit tests.
look for similar bugs
coach: are there other places in the ui where we display or change the status of a foobar?
dev: yes… maybe 3-4 screens and dialogs
coach: did we make the same mistake there?
dev: let’s quickly test the application. it would be quite embarassing if we got the same bug report for another screen…
dev: ooops! we made the same mistake in one other dialog. the other dialogs are ok.
coach: let’s note the dialog to be fixed and move on, because we’ve only got a few minutes left in our timebox and i’d like to do the next step first before fixing this bug.
dev: what more can we do?
make this type of problem impossible
now, before we fix the buggy dialog, we’ll apply the same safe refactorings to make the code testable, add tests to demonstrate the bug (and serve as regression tests once the bug is fixed) and then fix the bug. if we consistently test our viewmodel code and validate our viewmodel behaviour with the product manager, we’re less likely to overlook certain cases.
the fact that this bug appears in some dialogs and not in others tells us that we’re looking at different code. some code takes into account the “swizzledness” of a foobar, some code doesn’t.
but we can do better: why is this code duplicated? ideally, we’d want one instance of the code that decides which status options to show. otherwise, if the rules change (or more likely, if we discover we’ve missed an existing rule) we’ll have to remember to update all the pieces of code that determine status options of a foobar. so, once we’ve extracted and fixed the viewmodels from both our buggy dialogs, we’ll extract the common code that determines the status options. of course, this common code will have unit tests that verify this common behaviour.
afterwards, we’ll do the same to the dialogs that were implemented correctly. we can do this refactoring gradually, once the two bugs have been corrected. ideally, we’ll do this if we have to change the code of those dialogs anyway, to fix a bug or add a feature. even if we don’t touch these classes, we’ll make sure we refactor them within x time, so that we don’t have to remember these “dangling” refactorings too long.
some developers have taken the “swizzledness” into account, some haven’t. let’s share our findings with the team and the product manager. we may have to organise a session to clarify some of the subtleties of our domain. once they’re clear we can encode and document them as automated regression tests, so that we get a failing test next time we forget to take into account one of those subtleties.
 dev: hey, coach, your hour is up! shall we get a coffee?
coach: great! let’s step away from the keyboard 🙂
looking back (over a cup of coffee)
what have we done in 60 minutes?

isolated code that contains a bug from “untestable” code
added an automated test that shows the bug and can be run as a regression test after the fix
simplified the code by separating the viewmodel from the view
identified a new class of testable code, the viewmodels
found another bug before anyone noticed
we know how to make code testable and better factored for this type of bug
we know how to avoid this type of problem and be ready for changes in the domain

 looking forward
during the root cause analysis we noted a number of actions to be taken. we make each of these tasks visible (for example, by adding them to the kanban board):

extend the foobartest to cover more cases, in collaboration with the product manager and testers
test and fix the  second foobar status bug
make the code that determines the allowed status values common between the two bugfixed dialogs. validate tests with the product manager
refactor the other dialogs that display foobar statuses so that they use the common code
list the subtleties of the domain and organise a knowledge sharing session with the product manager
ask the team to review and discuss the anti-if campaign
let’s read some more about viewmodel architectures. if it looks useful we’ll make this a standard way of designing our user interfaces. if we do, we’ll have to see how we transition gradually to such an architecture.

dev: well… i never expected so many issues and ideas to come out of a root cause analysis of such a simple bugreport. let’s hope we don’t do too many of those root cause analyses, because they generate a lot of work.
coach: ????
dev: that was a joke, coach. 🙂  i’m sold. now, let’s get back and fix that bug we found.
 

april 2nd, 2013 |  category: agile, presentations, systems thinking 


    older entries »




event calendar

« jan





mar »


february 2025

m
t
w
t
f
s
s


 12
3456789
10111213141516
17181920212223
2425262728ec



archives 
december 2013 (1)
june 2013 (1)
may 2013 (1)
april 2013 (3)
march 2013 (1)
february 2013 (3)
november 2012 (1)
june 2011 (3)
april 2011 (6)
march 2011 (2)
february 2011 (1)
december 2010 (2)
november 2010 (1)
october 2010 (1)
september 2010 (6)
august 2010 (1)
july 2010 (1)
june 2010 (3)
may 2010 (3)
february 2010 (4)
january 2010 (7)
december 2009 (2)
november 2009 (2)
october 2009 (6)
september 2009 (7)
august 2009 (15)
july 2009 (6)
june 2009 (7)
may 2009 (9)
april 2009 (8)
march 2009 (6)
february 2009 (5)
january 2009 (5)
december 2008 (4)
november 2008 (7)
october 2008 (6)
september 2008 (4)
august 2008 (17)
july 2008 (7)
june 2008 (3)
may 2008 (5)
april 2008 (7)
march 2008 (5)
february 2008 (2)
january 2008 (3)
december 2007 (9)
november 2007 (9)
october 2007 (1)
july 2007 (1)
june 2007 (5)
may 2007 (7)
april 2007 (2)
december 2006 (3)
november 2006 (6)
october 2006 (13)
september 2006 (4)
august 2006 (2)
july 2006 (7)
june 2006 (2)
may 2006 (4)
april 2006 (11)
march 2006 (14)
february 2006 (7)
january 2006 (5)
december 2005 (12)
november 2005 (1)
october 2005 (3)
august 2005 (4)
july 2005 (22)










    copyright © 2025 thinking for a change - all rights reservedpowered by wordpress & the atahualpa wp theme by bytesforall. now with tutorials & support 








