



yann lecun's home page
















home
bio
publications
arxiv papers
g-scholar profile
software
cbll
research
teaching
what's new

djvu
lenet
mnist ocr data
norb dataset

music
photos
hobbies
fun stuff

links

cilvr
cds
cs dept
courant
nyu




websites that i maintain






 












yann lecun, 
chief ai scientist, meta
jacob t. schwartz professor of computer science, data science, neural science, and electrical and computer engineering, new york university.
acm turing award laureate, (sounds like i'm bragging, but a condition of accepting the award is to write this next to your name)
member, national academy of engineering, national academy of sciences, acadã©mie des sciences
fellow, acm, aaai, aaas, sif

last updated: 2024-07-14

social networks
threads/fediverse: @yannlecun (ml/ai, announcements, photos, politics)
linkedin: yann-lecun (ml/ai research and industry, announcements)
facebook: yann.lecun (general, science, ml/ai, culture, hobbies, photos)
bluesky: @yann-lecun.bsky.social (ml/ai, announcements)
twitter/x: @ylecun (i no longer write posts on x)

note: x has devolved into an antagonistic propaganda tool. as of
december 2024, i no longer write posts on x. as a favor to my numerous
followers, i tweet links to posts on other platforms (occasionally), i
retweet interesting contents from others (sometimes), and i comment on
tweets by friends (rarely). but i don't write substantial content.

biography / cv
curriculum vitae

bios of various lengths in english and en francais

contact information
nyu affiliations:
cilvr lab (computational intelligence, learning, vision, robotics), nyu
computer science department, courant institute of mathematical sciences, nyu
center for data science, nyu
center for neural science, nyu faculty of arts and sciences
department of electrical and computer engineering, nyu tandon school of engineering

meta affiliation:
meta fair (fundamental ai research)

assistants
executive assistant - meta: sean nguyen: sean0[at]meta.com
administrative aide - nyu: hong tam +1-212-998-3374     hongtam[at]cs.nyu.edu

for invitations to speak: please send email to lecuninvites[at]gmail.com
(i really can't handle invitations sent to other email addresses)

if you really need me to do something for you: (e.g. a review, a letter...) please send email to sean nguyen sean0[at]meta.com

nyu coordinates:
address: room 516, 60 fifth avenue, new york, ny 10011, usa.
email: yann.lecun[at]nyu.edu (i may not respond right away)
phone: +1-212-998-3283 (i am very unlikely to respond or listen to voice mail in a timely manner)

meta coordinates:
address: 380 w 33rd st, new york, ny 10001
email: yann[at]meta.com (i may not respond right away)

publications, talks, courses, videos, podcasts, interviews
publications:
google scholar
papers on openreview.net
preprints on arxiv
publications up to 2014 with pdf and djvu

talks / slide decks:
slides of (most of my) talks

deep learning course:
deep learning course at nyu:  complete course on deep learning, with all the material available on line including lectures and practicums, videos, slide decks, homeworks, jupyter notebooks, and transcripts in several languages.

videos:
playlists on youtube:

talks by yann lecun
lectures series by yann lecun
debates and panels with yann lecun
interviews of yann lecun
demos by yann lecun
six short videos to explain ai, machine learning, deep learning and convolutional nets (2016)

talks on videolectures: (from 2007 to 2016).


podcasts in english:

nikhil kamath, 11/2024 youtube "wtf is artificial intelligence really? | people by wtf ep #4" history of ai, how deep learning works, llms, jepa, the future of ai...
 lex friedman #416, 03/2024 youtube "meta ai, open source, limits of llms, agi & the future of ai"
 twenty minute vc with harry stebbing, 05/2023 podcast "yann lecun on why artificial intelligence will not dominate humanity..."
 with andrew ng, 04/2023 youtube "yann lecun and andrew ng: why the 6-month ai pause is a bad idea"
 big technology podcast with alex kantrowitz, 01/2023 youtube "is chatgpt a step toward human-level ai?"
 boz to the future with andrew bosworth, 08/2022 apple podcasts
eye on ai with craig smith #150 podcast "world models, ai threats and open sourcing"
 lex friedman #258, 01/2022 youtube "dark matter of intelligence and self-supervised learning"
 big technology podcast with alex kantrowitz, 12/2021 youtube "daniel kahneman and yann lecun: how to get ai to think like humans"
 the robot brains podcast with pieter abbeel, 09/2021 youtube "yann lecun explains why facebook would crumble without ai"
 the gradient podcast, 08/2021 the gradient "yann lecun on his start in research and self-supervised learning"
 ted with chris anderson, 06/2020 video "deep learning, neural networks and the future of ai"
 lex friedman #36, 08/2019 youtube "deep learning, convnets, and self-supervised learning"
 eye on ai with craig smith #114 podcast "filling the gap in llms"
 eye on ai with craig smith #017, 06/2019 video,podcast


podcasts en franã§ais:

generation diy #397 avec matthieu stefani 06/2024 podcast "lâintelligence artificielle gã©nã©rale ne viendra pas de chat gpt"
 toutes mes interviews sur france inter playlist
interview sur europe1 06/2023 podcast "yann lecun : â«l'intelligence artificielle va amplifier l'intelligence humaineâ»"
 interview sur france culture 10/2018 podcast sur youtube "yann lecun : les ã©motions sont insã©parables de l'intelligence"


main research interests:
ai, machine learning, computer vision,
robotics, and computational neuroscience.  i am also interested
physics of computation, and many applications of machine learning.

working paper

a path towards autonomous machine intelligence (june 2022)

  how could machines learn as efficiently as humans and animals?  how could machines learn to reason and plan?
  how could machines learn representations of percepts and action plans at multiple levels of abstraction,
  enabling them to reason, predict, and plan at multiple time horizons?
  this position paper proposes an architecture and training paradigms with which to construct autonomous
  intelligent agents. it combines concepts such as configurable predictive world model,
  behavior driven through intrinsic motivation, and hierarchical joint embedding architectures
  trained with self-supervised learning.

recent lecture on the topic: "how could machines reach human-level intelligence?"
  distinguished lecture at columbia university, 2024-10-18.
video on youtube
slide deck

books

quand la machine apprend 
la revolution des neurones artificiels et de l'apprentissage profond (editions odile jacob, octobre 2019)
exists in chinese, japanese, and russian.

la plus belle histoire de l'intelligence 
des origines aux neurones artificiels : vers une nouvelle ã©tape de l'ã©volution
stanislas dehaene, yann le cun, jacques girardon (ãditions robert laffont, octobre 2018)

pamphlets and opinions

address to the un security council, 2024-12-19

i was invited by secretary of state antony blinken to speak about ai at the
un security council meeting on 2024-12-19.  i was followed by
fei-fei li, and representatives from unsc member states.

in my speech, i argued for free/open source foundation models and for
international cooperation to train "universal" foundation models that
speak all the languages in the world and understand all cultures and
value systems.

my speech starts at the 00:12:20 mark in this video

proposal for a new publishing model in computer science

many computer science researchers are complaining that our emphasis on
highly selective conference publications, and our double-blind
reviewing system stifles innovation and slow the rate of progress
of science and technology.

this pamphlet proposes a new publishing model based on an open repository
and open (but anonymous) reviews which creates a "market" between papers
and reviewing entities.

students and postdocs
current phd students

basile terver (fair-ens with jean ponce) [ssl for control and planning]
gaoyue ''kathy'' zhou (nyu cs with lerrel pinto) [ssl for control and planning]
shengbang ''peter'' tong (nyu cs with saining xie) [ssl for video]
wangcong ''kevin'' zhang (nyu cs) [ssl for planning]
megi dervishi (fair-universitã© paris-dauphine with alexandre allauzen) [ssl for text]
quentin garrido (fair-universitã© gustave eiffel with laurent najman) [ssl for images and video]
jiachen zhu (nyu cs) [ssl and optimization]
vlad sobal (nyu cds) [ssl for planning and control]


current postdocs

 oumayma bounou (nyu) [planning]  
 amir bar (fair) [ssl for video]
 ravid schwartz-ziv (nyu) [ssl and information theory]
 gelareh naseri (nyu) [music synthesis and composition]


former phd students

 alexander rives (2024 nyu cs) [protein design] fair, ceo evolutionary scale, mit eecs & broad institute.
 katrina drozdov evtimova (2024 nyu cds) [latent variable jepa]
 adrien bardes (2024 fair-inria with jean ponce) [ssl, vicreg, i-jepa, v-jepa]. fair
 zeming lin (2023 nyu cs) [transformers for protein structure]. fair, evolutionaryscale ai
 aishwarya kamath (2023 nyu cds) [vision-language models] deepmind
 junbo ``jake'' zhao (2019 nyu cs) [energy-based models] faculty zhejiang university
 xiang zhang (2018 nyu cs) [deep learning for nlp] element ai, google ai, startup
 mikael henaff (2018 nyu cs) [deep learning for control] microsoft research, fair
 remi denton (2018 nyu cs, with rob fergus) [video prediction] google
 sainbayar sukhbaatar (2018, nyu cs with rob fergus) [memory, intrinsic motivation, multiagent communication] fair
 michael mathieu (2017 nyu cs) [dl for video prediction and image understanding] deepmind
 jure zbontar (2016 u. of ljubljana, co-advised) [dl for stereo vision] nyu, fair, openai
 sixin zhang (2016 nyu cs) [paralellized deep learning] ens-paris, faculty institut national polytechnique de toulouse
 wojciech zaremba (2016 nyu cs with rob fergus) [algorithm synthesis] openai
 rotislav goroshin (2015 nyu cs) [unsupervised representation learning] deepmind
 pierre sermanet (2014 nyu cs) [dl for vision and mobile robot perception] google brain, deepmind
 clã©ment farabet (2014 u. gustave eiffel with laurent najman) [dedicated hardware for convnets, vision, torch-7] twitter, nvidia, vp of research deepmind
 fu jie huang (2013 nyu cs) [dl for vision] milabra, kanerai
 kevin jarrett (2012 nyu neural science) [dl models of biological vision] bridgewater,...,barclays
 matthew grimes (2012 nyu) [slam] cambridge, deepmind
 y-lan boureau (2012, nyu-inria with jean ponce) [sparse feature learning for vision] flatiron institute, fair, ceo thrivepal)
 koray kavukcuoglu (2010, nyu) [sparse auto-encoders for unsupervised feature learning] nec labs, vp of genai deepmind
 piotr mirowski (2010 nyu) bell labs, microsoft, deepmind
 ayse naz erkan (2010 nyu, with yasemine altun) twitter, robinhood, ceo laminar ai.
 marc'aurelio ranzato (2009 nyu) google x-labs, fair, deepmind.
 sumit chopra (2008 nyu) at&t labs-research, fair, imagen, faculty nyu.
 raia hadsell (2008 nyu) sri, vp foundations deepmind
 feng ning (2006 nyu) bank of america, sociã©tã© gã©nã©rale, scotiabank, aqr capital, vp alliancebernstein.


former postdocs

 micah goldblum (nyu 2021-2024), columbia university
 grã©goire mialon (fair 2021-2023), meta-genai
 randall balestriero (fair 2021-2023), brown university
 nicolas carion (nyu 2020-2022), fair
 yubei chen (fair 2020-2022), uc davis
 li jing (fair 2019-2021), openai
 jacob browning (nyu 2019-2023): philosophy and history of ai (berggruen transformation of the human program)
 phillip schmitt (nyu 2019-2021): ai and the visual arts (berggruen transformation of the human program)
 stã©phane deny (fair 2019-2021), u of aalto
 alfredo canziani (nyu 2017-2022), nyu: autonomous driving, ai education
 behnam neyshabur (nyu 20172019), google, deepmind: deep learning landscape, self-supervised learning
 jure zbontar (nyu 2016-2017). fair, openai: temporal prediction
 anna choromanska (nyu 2014-2017) nyu tandon: applied mathematics
 pablo sprechmann (nyu 2014-2017), deepmind: applied mathematics and signal processing
 joan bruna (nyu 2012-2014), fair, uc berkeley, nyu: applied mathematics
 camille couprie (nyu 2011-2013), fair: computer vision
 tom schaul (nyu 2011-2013), deepmind: machine learning and optimization
 jason rolfe (nyu 2011-2013), d-wave, variational ai: computational neuroscience
 leo zhu (nyu 2010-2011), ceo yitu: hierarchical vision models.
 arthur szlam (nyu 2009-2011), cuny, fair, deepmind: applied mathematics.
 karol gregor (nyu 2008-2011), janelia farm, deepmind: machine learning.
 trivikraman thampy (nyu 2008-2009), ceo play games24x7: financial modeling and prediction.
 joseph turian (nyu 2007-2007), founder metaoptimize: energy-based models.

bragging zone
honors and awards

queen elizabeth prize for engineering, 2025 (shared with yoshua bengio, geoffrey hinton, john hopfiels (foundations), bill dally, jensen huang (hardware), fei-fei li (data). [link]
ams josiah willard gibbs lecturer, jmm seattle, 2025, [link]
vinfuture grand prize, 2024 (shared with yoshua bengio, geoff hinton, jensen huang, fei-fei li), [link], [acceptance speech], [pictures]
trailblazer in science award, new york hall of science, 2024, [link]
doctorate honoris causa, universitã© de genã¨ve, 2024, [link], [lecture]
professor honoris causa, esiee / universitã© gustave eiffel, 2024, [link]
lifetime honorary membership, new york academy of sciences, 2024, [link]
fellow association for computing machinery, 2024, [link]
great immigrant, carnegie corporation of new york, 2024, [link]
time 100 impact award, 2024, [link], [pictures]
membre d'honneur, sociã©tã© informatique de france, 2024, [link]
chevalier de la lã©gion d'honneur, france, 2020/2023, [link], [pictures]
global swiss ai award for outstanding global impact in the field of artificial intelligence, 2023, [link], [pictures]
inaugural professorship, jacob t. schwartz chair in computer science, courant institute, nyu. 2023, [link]
doctorate honoris causa, hong kong university of science and technology, 2023, [link], [pictures]
doctorate honoris causa, universitã  di siena, 2023, [link], [pictures]
princess of asturias award, for technical and scientific research (with demis hassabis, yoshua bengio, and geoffrey hinton), 2022, [link], [pictures]
foreign member, acadã©mie des sciences, france, 2022, [link], [video at 00:53:58]
fellow, american association for the advancement of science, 2021, [link]
member, us national academy of sciences, 2021, [link], [pictures]
doctorate honoris causa, universitã© cã´te d'azur, 2021, [link]
fellow, association for the advancement of artificial intelligence, 2020, [link]
golden plate award, international academy of achievement, 2019, [link]
acm a.m. turing award, 2018 (shared with geoffrey hinton and yoshua bengio), [link], [pictures]
doctorate honoris causa, ecole polytechnique fã©dã©rale de lausanne, 2018, [link]
holst medal, technical university of eindhoven and philips labs, the netherlands
pender award, university of pennsylvania, 2018, [link]
member, us national academy of engineering, class of 2017, [link]
nokia-bell labs shannon luminary award, 2017, [interview] [lecture]
annual chair in computer science, collã¨ge de france 2015-2016. [link]
lovie lifetime achievement award, international academy of digital arts and sciences, 2016. [link to acceptance speech]
inductee, new jersey inventor hall of fame, 2016. [link]
doctorate honoris causa, instituto politã©cnico nacional, mexico, 2016. [link]
ieee pattern analysis and machine intelligence distinguished researcher award, 2015. [link]
ieee neural network pioneer award, 2014. [link]
nyu silver professorship, 2008.
fyssen foundation fellowship, 1987.


in the media


more than one ai revolution? yann lecun on tech trajectories (john werner, forbes, 02/2025)
  yann le cun, vigie internationale de l'ia (la tribune, 02/2025)
 yann lecun : â«lâagi dans quelques annã©esâ¯? câest simplement fauxâ¯!â» (it for business, 02/2025)    
 ia : yann le cun au micro de bfm business (bfm tv business, 02/2025)  
 sommet de lâia : meta dã©voile sa vision de lâavenir de lâintelligence artificielle (bye-bye les robots conversationnels) (20minutes.fr, 02/2025)  
 ai âgodfatherâ predicts another revolution in the tech in next five years (the guardian, 02/2025)  
 machine-learning pioneer yann lecun on why âa new revolution in aiâ is coming (the economist, 02/2025)
 meta engineers see vindication in deepseekâs apparent breakthrough (new york times, 01/2025)
 chatgpt, deepseek, or llama? metaâs lecun says open-source is the key (forbes, 01/2025)     
 meta's chief ai scientist says market reaction to deepseek was 'woefully unjustified.' here's why (business insider, 01/2025)
 metaâs yann lecun predicts ânew paradigm of ai architecturesâ within 5 years and âdecade of roboticsâ (tech crunch, 01/2025)     
 security council debates use of artificial intelligence in conflicts, hears calls for un framework to avoid fragmented governance (united nations press, 12/2024)    
 how mark zuckerberg has fully rebuilt meta around llama (fortune, 11/2024)  
 âopen-source will winâ: metaâs yann lecun takes aim at competitorsâ closed ai models (business today india, 10/2024)    
 future of ai will be like waking with three smart people working for you (the times of india, 10/2024)  
 this ai pioneer thinks ai is dumber than a cat (wall street journal, 10/2024)
  ai safety showdown: yann lecun slams californiaâs sb 1047 as geoffrey hinton backs new regulations (venturebeat, 08/2024)
  yann le cun (meta), rock star discrã¨te de la tech et de lâia (challenges, 06/2024)
  meta ai chief lecun slams elon musk over âblatantly falseâ predictions, spreading conspiracy theories (cnbc, 06/2024)
  'new renaissance': meta and amazon bosses make the case for ai optimism  (cnn, 06/2024)    
  what is science? tech heavyweights brawl over definition (nature, 05/2024)    
  ai pioneer lecun to next-gen ai builders: don't focus on llms (venturebeat, 05/2024)
  social media feud highlights key differences in approach to ai research and hype (venturebeat, 05/2024)  
  elon musk is feuding with âai godfatherâ yann lecun (again)âhere's why (forbes, 05/2024)
  meta ai chief says large language models will not reach human intelligence. yann lecun argues current ai methods are flawed as he pushes for âworld modellingâ vision for superintelligence (financial times, 05/2024) 
  time 100 impact award: yann lecun is optimistic that ai will lead to a better world (time, 02/2024)
  metaâs ai chief yann lecun on agi, open-source, and ai risk (time, 02/2024)
  yann lecun, chief ai scientist at meta: human-level artificial intelligence is going to take a long time (el pais, 01/2024)
  how not to be stupid about ai, with yann lecun (wired magazine, 12/2023)
  inside the a.i. arms race that changed silicon valley forever (new york times, 12/2023)    
  ai pioneers yann lecun and yoshua bengio clash in an intense online debate over ai safety and governance (venture beat, 10/2023)    
  in a rare outburst, metaâs lecun blasts openai, turing awardees. meta chief ai scientist yann lecun is blasting fellow ai luminaries for overselling ai's existential threat and asking for regulation (ai business, 10/2023)
  why metaâs yann lecun isnât buying the ai doomer narrative (fastcompany, 05/2023)    
  in battle over a.i., meta decides to give away its crown jewels (new york times, 05/2023)
  yann le cun, directeur ã  meta : â« lâidã©e mãªme de vouloir ralentir la recherche sur lâia sâapparente ã  un nouvel obscurantisme â» (le monde, 04/2023)
  yann le cun, director at meta: 'the very idea of wanting to slow down ai research is akin to a new form of obscurantism' (le monde 04/2023)
  yann lecunâs vision for creating autonomous machines (venturebeat, 08/2022)    
  yann lecun has a bold new vision for the future of ai (mit tech review 06/2022)
   yann lecun: ai doesnât need our supervision. metaâs ai chief says self-supervised learning can build the metaverse and maybe even human-level ai  (ieee spectrum 02/2022)
  turing award won by 3 pioneers in artificial intelligence (new york times 03/2019)    
  inside facebook's fight to beat google and dominate in ai (wired 11/2018)
  facebook ai chief yann lecun is stepping aside to take on dedicated research role (the verge 01/2018)
  portrait: yann lecun, le temps des machines (libã©ration, 09/2015)
  intelligent machines: what does facebook want with ai? (bbc, 09/2015)    
  teaching machines to understand us (mit tech review, 08/2015)
  welcome to the ai conspiracy: the 'canadian mafia' behind tech's latest craze (vox, 07/2015)
  facebook opens a paris lab as ai research goes global (wired, 06/2015)        
  yann lecun, lâintelligence en rã©seaux. adulã© dans sa spã©cialitã©, le â« deep learning â», ce chercheur recrutã© par facebook dirige le laboratoire dâintelligence artificielle crã©ã© ã  paris par le rã©seau social. (le monde, 06/2015)
  yann lecun : â«âlâintelligence artificielle reste un dã©fi scientifiqueââ» (les echos, 06/2015)
  'deep learning' will soon give us super-smart robots (wired, 05/2015)        
  facebook's quest to build an artificial brain depends on this guy (wired 08/2014)
  facebook's 'deep learning' guru reveals the future of ai (wired 12/2013)
  facebook taps 'deep learning' giant for new ai lab (wired 12/2013)    
  eye robot (the economist, 10/2010)

older content

[stuff below this line is badly out of date]



quick links

center for data science, and the nyu data science portal.
computational and
  biological learning lab, my research group at the courant institute, nyu.
cilvr lab: computational intelligence, vision robotics lab: a lab with many nyu faculty, students and postdocs working on ai, ml and applications thereof such as computer vision, nlp, robotics, and healthcare.
research: descriptions
    of my projects and contributions, past and present.
publications: (almost) all of my
    publications, available in pdf and djvu formats.
google
   scholar profile: all my publications with number of citations,
   harvested by google.
preprints on arxiv.org: 
   where you will find our latest results, before they may receive a stamp of approval.


computational and biological learning lab

 my lab at the courant institute of new york university is
called the computational and biological learning
lab. 




see research projects
descriptions, lab member pages, events, demos, datasets...

we are working on a class of learning systems called energy-based
models, and deep belief networks. 
we are also working on convolutional nets for visual recognition , and a type 
of graphical models known as factor graphs.

we have projects in computer vision, object detection, object
recognition, mobile robotics, bio-informatics, biological image
analysis, medical signal processing, signal processing, 
and financial prediction,....



teaching

jump to
my course page at nyu,
and see course descriptions, slides, course material...

talks and tutorials

see, watch and hear talks and tutorial.

deep learning

animals and humans can learn to see, perceive, act, and communicate
with an efficiency that no machine learning method can approach.  the
brains of humans and animals are "deep", in the sense that each action
is the result of a long chain of synaptic communications (many layers
of processing).  we are currently researching efficient learning
algorithms for such "deep architectures". we are currently
concentrating on unsupervised learning algorithms that can be used to
produce deep hierarchies of features for visual recognition. we
surmise that understanding deep learning will not only enable us to
build more intelligent machines, but will also help us understand
human intelligence and the mechanisms of human learning.

more information >>>>>.


relational regression

we are developing a new type of relational graphical models that can
be applied to "structured regression problem".  a prime example of
structured regression problem is the prediction of house prices. the
price of a house depends not only on the characteristics of the house,
but also of the prices of similar houses in the neighborhood, or
perhaps on hidden features of the neighborhood that influence
them. our relational regression model infers a hidden "desirability
sruface" from which house prices are predicted.

more information >>>>>.


mobile robotics

the purpose of the lagr project,
funded by the us government, is to design vision and learning algorithms
to allow mobile robots to navigate in complex outdoors 
environment solely from camera input.

my lab, collaboration with 
net-scale
technologies is one of 8 participants in the program
(applied perception inc., georgia tech, jpl, nist, nyu/net-scale, 
sri, u. penn, stanford).

each lagr team received identical copies of the 
lagr robot, 
built be the cmu/nrec.





the government periodically runs competitions between the teams.
the software from each team is loaded and run by the goverment team
on their robot. 

the robot is given the gps coordinates of a goal to which it must
drive as fast as possible.  the terrain is unknown in advance.
the robot is run three times through the test course.

the software can use the knowledge acquired during the early 
runs to improve the performance on the latter runs.





click here for more information, videos, pictures >>>>>.

prior to the lagr project, we worked on the 
dave project, 
an attempt to train a small mobile robot to drive autonomously in 
off-road  environments by looking over the shoulder of a human operator.

click here for information on the dave project >>>>>.

energy-based models

energy-based models (ebms) capture dependencies between variables by
associating a scalar energy to each configuration of the
variables. inference consists in clamping the value of observed
variables and finding configurations of the remaining variables that
minimize the energy. learning consists in finding an energy
function in which observed configurations of the variables are given
lower energies than unobserved ones. the ebm approach provides a
common theoretical framework for many learning models, including
traditional discriminative and generative approaches, as well as
graph-transformer networks, conditional random fields, maximum margin
markov networks, and several manifold learning methods.

probabilistic models must be properly normalized, which sometimes
requires evaluating intractable integrals over the space of all
possible variable configurations. since ebms have no requirement for
proper normalization, this problem is naturally circumvented.  ebms
can be viewed as a form of non-probabilistic factor graphs, and they
provide considerably more flexibility in the design of architectures
and training criteria than probabilistic approaches.






click here for
more information, pictures, papers >>>>>.

invariant object recognition







the recognition of generic object categories with invariance to pose,
lighting, diverse backgrounds, and the presence of clutter is one of
the major challenges of computer vision. 

i am developing learning systems that can recognize generic object
purely from their shape, independently of pose and lighting.

see 

the norb dataset for generic object recognition is 
available for download.





click here for more information, pictures, papers >>>>>.

lush: a programming language for research

tired of matlab? lush is an
easy-to-learn, open-source object-oriented programming language
designed for researchers, experimenters, and engineers working in
large-scale numerical and graphic applications.  

lush combines three languages in one: a very simple to use,
loosely-typed interpreted language, a strongly-typed compiled language
with the same syntax, and the c language, which can be freely mixed
with the other languages within a single source file, and even
within a single function.



lush has a library of over 14,000 functions and classes, 
some of which are simple interfaces to popular libraries: 
vector/matrix/tensor algebra, linear algebra (lapack, blas), 
numerical function (gsl), 2d and 3d graphics (x, sdl, opengl, 
openrm, postscipt), image processing, computer vision (opencv),
machine learning (gblearning, torch), regular expressions,
audio processing (alsa), and video grabbing (video4linux).

if you do research and development in signal processing, image
processing, machine learning, computer vision, bio-informatics, data
mining, statistics, or artificial intelligence, and feel limited by
matlab and other existing tools, lush is for you. if you want a 
simple environment to experiment with graphics, video, and sound, 
lush is for you. lush is free software (gpl) and runs under gnu/linux,
solaris, and irix.

visit the lush home page >>>>


djvu: the document format for digital libraries


my main research topic until i left at&t was the
djvu project.
djvu is a document format, a set of compression methods and a software
platform for distributing scanned and digitally produced documents on the web.
djvu image files of scanned documents are typically 3-8 times 
smaller than pdf or tiff-groupiv for bitonal and 5-10 times 
smaller than pdf or jpeg for color (at 300 dpi). djvu versions
of digitally produced documents are more compact and render 
much faster than the pdf or postscript versions.

hundreds of websites
around the world are using djvu for web-based and cdrom-based
document repositories and digital libraries. 

yann's djvu page: 
    a description of djvu, and a set of useful links.
technical talk on djvu:
    watch a streaming video of yann's distinguished lecture
    at the university of illinois at urbana-champaign, october 22 2001.
    (100k windows streaming media).
    (56k windows streaming media),
djvuzone.org: 
    samples, demos, technical information, papers, and tutorials on djvu....
    djvuzone hosts several digital libraries, including 
    nips online.
djvulibre for unix: free/open-source
    browser plug-ins, viewers, utilites, and libraries for unix.
commercial djvu software:
    free plug-ins for windows and mac, free and commercial applications
    for windows and some unix platforms (hosted at
    lizardtech, the company 
    that distributes and supports djvu under license from at&t).
any2djvu and 
    bib2web: upload
    your documents and get them converted to djvu. bib2web automates
    the creation of 
    publication pages for researchers.



learning and visual perception

my main research interest is machine learning, particularly how it applies
to perception, and more particularly to visual perception.

i am currently working on two architectures for gradient-based perceptual
learning: graph transformer networks and convolutional networks.

convolutional nets are a special kind of neural net architecture designed 
to recognize images directly from pixel data. convolutional nets can be
trained to detect, segment and recognize objects with excellent robustness
to noise, and variations of position, scale, angle, and shape.

have a look at the animated 
demonstrations of lenet-5, 
a convolutional nets trained to recognize handwritten digit strings.

convolutional nets and graph transformer networks are embedded in 
several high speed scanners used by banks to read checks.
a system i helped develop reads an estimated 10 percent of
all the checks written in the us.

check out this page, and/or 
read this paper
to learn more about convolutional nets and graph transformer networks.

mnist handwritten digit database

the mnist database contains 
60,000 training samples and 10,000 test samples of size-normalized
handwritten digits. this database was derived from the original
nist databases.

mnist is widely used by researchers as a benchmark for testing 
pattern recognition methods, and by students for class projects
in pattern recognition, machine learning, and statistics.

music and hobbies

i have several interests beside my family (my wife and three sons)
and my research: 

playing music: particularly jazz, renaissance
    and baroque music. a few mp3 and midi files of renaissance music are 
    available here. 
building and flying miniature flying contraptions:
    preferably battery powered, radio controled, and unconventional in their design.
    
building robots: particularly lego robots (before the days of the lego mindstorms)
hacking various computing equipment:
    i have owned 5 computers between 1978 and 1992: sym-1, osi c2-4p, commodore 64, 
    amiga 1000, amiga 4000. then i lost interest in personal computing when the only thing
    you could get was a boring wintel box. then, linux appeared and i came back to life.....
sailing: i own two sport catamarans, a nacra 5.8 and a prindle 19. i also sail 
    and race larger boats with friends.
graphic design: i designed the djvu logo and much of the at&t djvu web site.
reading european comics. comics in certain european countries (france, belgium, italy,
   spain) are considered a true art form ("le 8-ieme art"), and not just a business with
   products targeted at teenagers like on this side of the pond. although i don't have
   a shred of evidence to support it, i claim to have the largest private collection 
   of french-language comics in the eastern us. 
making bad puns in french, but i don't 
    have much of an audience this side of the pond.
sipping wine, particularly red, particularly french,
    particularly bordeaux, particularly saint-julien.


bib2web: automatic creation of publication pages


no deep science here, but if you are looking for a simple/automatic way to make all your 
publications (digital or paper-based) available on your web page, 
visit bib2web.


photos galleries

photos taken at various conferences,
     workshops, trade shows and other professional events. includes
     pictures from cvpr, nips, learning@snowbird, icdar, cifed, etc.
a photo and movie gallery of various 
    radio-controled airplanes, other miniature flying objects,
    lego robots, and other techno toys. check out also my 
    model airplane page.
miscellaneous artsy and nature picture,
    including garden-variety wild animals, landscapes, etc.
vintage airplanes at
    the national air and space museum in le bourget, near paris.


fun stuff

no, yann is not philippe kahn's evil brother
your name can't possibly be pronounced that way: 
or how a nobel prize winner tried to tell me how to pronounce my own name.
who is tex avery anyway?
steep learning curves and other 
erroneous metaphores
vladimir vapnik meets the 
video game sub-culture
cheap philosophy (42 cents)
a mathematical theory of empty disclaimers
the axis of rivals

previous life

my former group at at&t (the image processing research department)
and its ancestor (larry jackel's adaptive systems research department)
made numerous contributions to machine learning, image compression,
pattern recognition, synthetic persons (talking heads), and neural-net
hardware. specific contributions not mentioned elsewhere on this site
include the ever so popular support vector machine, the playmail and 
virt2elle synthetic talking heads, the net32k and anna neural net chips, 
and many others. 
visit my former group's home page 
for more details.  
links

links to interesting places on the web, friends'
home pages, etc .












[home]
[news]
[publications]


[research]
[downloads]


[lenet]
[music]
[photos]


[hobbies]
[fun]
[links]






yann lecun, professor
the courant institute of mathematical sciences




copyright â© 2000-2018 yann lecun.



yann lecun, le cun, deep learning, convnet, cnn, lenet, djvu, 
convolutional neural networks, machine learning, computer vision, 
pattern recognition, document imaging, image compression, 
digital libraries,


