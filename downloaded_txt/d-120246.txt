



















weights & biases: the ai developer platform









































































































 











skip to content








 







 

 





 




							platform						
 

close platform


open platform









models: mlops solution 







 
experimentstrack and visualize your ml experiments





 
 sweepsoptimize your hyperparameters





 
 registrypublish and share your ml models and datasets





 
  automationstrigger workflows automatically









weave: llmops solution 







 
tracesexplore and debug llm applications





 
evaluationsrigorous evaluations of genai applications









core platform 







 
 artifactsversion and manage your ml pipelines





 
 tablesvisualize and explore your ml data





 
 reportsdocument and share your ml insights





 
 sdklog ml experiments and artifacts at scale












 




							solutions						
 

close solutions


open solutions










use cases 




develop with llms
train llms
fine-tune llms
computer vision
time series
recommender systems
classification & regression
 

develop with llms
train llms
fine-tune llms
computer vision
time series
recommender systems
classification & regression
 






industries 




autonomous vehicles
communications
financial services
healthcare and life sciences
public sector
scientific research
 

autonomous vehicles
communications
financial services
healthcare and life sciences
public sector
scientific research
 










 




							enterprise						
 

close enterprise


open enterprise










mlops for enterprise
w&b for teams
deployment options
build vs. buy
mlops maturity assessment
security
genai accelerator: master class
genai accelerator: consulting services
 

mlops for enterprise
w&b for teams
deployment options
build vs. buy
mlops maturity assessment
security
genai accelerator: master class
genai accelerator: consulting services
 









 




							resources						
 

close resources


open resources












resource library
case studies
whitepapers
articles
partners
 

resource library
case studies
whitepapers
articles
partners
 







blog & tutorials
events
ai courses
gradient dissent podcast
support
 

blog & tutorials
events
ai courses
gradient dissent podcast
support
 











 




							company						
 

close company


open company










careers
trust & security
legal
about us
 

careers
trust & security
legal
about us
 









 
							docs						
 



 
							pricing						
 













log in










sign up







kojaende








 















 








 





our ai programming agent is state of the art on swe-bench verified! 





message from our cto 





 






















        ai is
        

                easy
                




















        to 
            productionize
        

 



the ai developer platform to build ai applications and models with confidence 










 




							w&b weave: develop ai applications						













				
					import weave
weave.init("quickstart")
@weave.op()
def llm_app(prompt):
    pass # track llm calls, document retrieval, agent steps
				
			










get started with weave















 




							w&b models: build ai models						













				
					import wandb
run = wandb.init(project="my-model-training-project")
run.config = {"epochs": 1337, "learning_rate": 3e-4}
run.log({"metric": 42})
my_model_artifact = run.log_artifact("./my_model.pt", type="model")








				
			










get started with models 














request demo























the world’s leading ai teams trust weights & biases
 







 







 
















 
meet our customers













weights & biases ai developer platform 



 









get started with one line of code  







“i love weave for a number of reasons. the fact that i could just add a library to our code and all of a sudden i’ve got a whole bunch of information about the genai portion of our product, in weights & biases, which i was already using and very familiar with. all those things that i’m watching for the performance of our ai, i can now report on quickly and easily with weave.” 














 





mike maloney, co-founder and cdo 



neuralift 





















  

				integrate quickly			



  

				langchain			



  

				llamaindex			



  

				pytorch			



  

				hf transformers			



  

				lightning			



  

				tensorflow			



  

				keras			



  

				scikit-learn			



  

				xgboost			








				
					import openai, weave
weave.init("weave-intro")

@weave.op
def correct_grammar(user_input):
    client = openai.openai()
    response = client.chat.completions.create(
        model="o1-mini",
        messages=[{
            "role": "user", 
            "content": "correct the grammar:\n\n" + 
            user_input,
        }],
    )
    return response.choices[0].message.content.strip()

result = correct_grammar("that was peace of cake!")
print(result)
				
			









				
					import weave
from langchain_core.prompts import prompttemplate
from langchain_openai import chatopenai

# initialize weave with your project name
weave.init("langchain_demo")

llm = chatopenai()
prompt = prompttemplate.from_template("1 + {number} = ")

llm_chain = prompt | llm

output = llm_chain.invoke({"number": 2})

print(output)
				
			









				
					import weave
from llama_index.core.chat_engine import simplechatengine

# initialize weave with your project name
weave.init("llamaindex_demo")

chat_engine = simplechatengine.from_defaults()
response = chat_engine.chat(
    "say something profound and romantic about fourth of july"
)
print(response)
				
			









				
					import wandb
# 1. start a new run
run = wandb.init(project="gpt5")
# 2. save model inputs and hyperparameters
config = run.config
config.dropout = 0.01
# 3. log gradients and model parameters
run.watch(model)
for batch_idx, (data, target) in enumerate(train_loader):
...
   if batch_idx % args.log_interval == 0:
   # 4. log metrics to visualize performance
      run.log({"loss": loss})
				
			









				
					import wandb
‍
# 1. define which wandb project to log to and name your run
run = wandb.init(project="gpt-5",
run_name="gpt-5-base-high-lr")
‍
# 2. add wandb in your `trainingarguments`
args = trainingarguments(..., report_to="wandb")
‍
# 3. w&b logging will begin automatically when your start training your trainer
trainer = trainer(..., args=args)
trainer.train()
				
			









				
					from lightning.pytorch.loggers import wandblogger

# initialise the logger
wandb_logger = wandblogger(project="llama-4-fine-tune")

# add configs such as batch size etc to the wandb config
wandb_logger.experiment.config["batch_size"] = batch_size

# pass wandb_logger to the trainer 
trainer = trainer(..., logger=wandb_logger)

# train the model
trainer.fit(...)

				
			









				
					import wandb
# 1. start a new run
run = wandb.init(project="gpt4")
‍
# 2. save model inputs and hyperparameters
config = wandb.config
config.learning_rate = 0.01
‍
# model training here
# 3. log metrics to visualize performance over time
‍
with tf.session() as sess:
# ...
wandb.tensorflow.log(tf.summary.merge_all())
				
			









				
					import wandb
from wandb.keras import (
   wandbmetricslogger,
   wandbmodelcheckpoint,
)
‍
# 1. start a new run
run = wandb.init(project="gpt-4")
‍
# 2. save model inputs and hyperparameters
config = wandb.config
config.learning_rate = 0.01
...  # define a model
# 3. log layer dimensions and metrics
wandb_callbacks = [
   wandbmetricslogger(log_freq=5),
   wandbmodelcheckpoint("models"),
]
model.fit(
   x_train, y_train, validation_data=(x_test, y_test),
   callbacks=wandb_callbacks,
)
				
			









				
					import wandb
wandb.init(project="visualize-sklearn")
‍
# model training here
# log classifier visualizations
wandb.sklearn.plot_classifier(clf, x_train, x_test, y_train, y_test, y_pred, y_probas, labels,
model_name="svc", feature_names=none)
‍
# log regression visualizations
wandb.sklearn.plot_regressor(reg, x_train, x_test, y_train, y_test,  model_name="ridge")
‍
# log clustering visualizations
wandb.sklearn.plot_clusterer(kmeans, x_train, cluster_labels, labels=none, model_name="kmeans")
				
			









				
					import wandb
from wandb.xgboost import wandb_callback
‍
# 1. start a new run
run = wandb.init(project="visualize-models")
‍
# 2. add the callback
bst = xgboost.train(param, xg_train, num_round, watchlist, callbacks=[wandb_callback()])
‍
# get predictions
pred = bst.predict(xg_test)
				
			

























see the weights & biases ai developer platform in action  










sign up










request demo




















 







x-twitter
 



linkedin-in
 



youtube
 











the platform 




experiments
sweeps
registry
automations
weave​
traces
evaluations
artifacts
tables
reports
 

experiments
sweeps
registry
automations
weave​
traces
evaluations
artifacts
tables
reports
 






article 




what is mlops?
experiment tracking
ml model registry
data and model versioning
llm evaluations
 

what is mlops?
experiment tracking
ml model registry
data and model versioning
llm evaluations
 






resources 




documentation
ai courses
community forum
articles
blog and tutorials
podcast
events
support
 

documentation
ai courses
community forum
articles
blog and tutorials
podcast
events
support
 






company 




about us
partners
trust and security
legal
brand guide
contact
press
 

about us
partners
trust and security
legal
brand guide
contact
press
 















copyright © weights & biases. all rights reserved. 






website terms of use
privacy policy
english

日本語 (japanese)
한국어 (korean)
deutsch (german)


 

website terms of use
privacy policy
english

日本語 (japanese)
한국어 (korean)
deutsch (german)


 











 






 

 





 




							platform						
 

close platform


open platform












 
experimentslightweight experiment tracking





 
 reportscollaborative dashboards





 
 artifactsdataset and model versioning





 
 tablesinteractive data visualization





 
 sweepshyperparameter optimization





 
  modelscentralized model registry





 
launchautomated ml workflows





 
promptsllmops and prompt engineering





 
monitoringobservability for production ml





 
weaveinteractive ml app builder











 




							solutions						
 

close solutions


open solutions











use cases 




website terms of use
master service agreement
sla
support policy
dpa
privacy policy
modern slavery statement
 

website terms of use
master service agreement
sla
support policy
dpa
privacy policy
modern slavery statement
 






industries 




website terms of use
master service agreement
sla
support policy
dpa
privacy policy
modern slavery statement
 

website terms of use
master service agreement
sla
support policy
dpa
privacy policy
modern slavery statement
 











 




							ecosystem						
 

close ecosystem


open ecosystem












website terms of use
master service agreement
sla
support policy
dpa
privacy policy
modern slavery statement
 

website terms of use
master service agreement
sla
support policy
dpa
privacy policy
modern slavery statement
 







website terms of use
master service agreement
sla
support policy
dpa
privacy policy
modern slavery statement
 

website terms of use
master service agreement
sla
support policy
dpa
privacy policy
modern slavery statement
 











 
							docs						
 



 
							pricing						
 



 




							enterprise						
 

close enterprise


open enterprise










website terms of use
master service agreement
sla
support policy
dpa
privacy policy
modern slavery statement
 

website terms of use
master service agreement
sla
support policy
dpa
privacy policy
modern slavery statement
 









 




							company						
 

close company


open company










website terms of use
master service agreement
sla
support policy
dpa
privacy policy
modern slavery statement
 

website terms of use
master service agreement
sla
support policy
dpa
privacy policy
modern slavery statement
 

































































