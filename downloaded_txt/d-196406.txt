




adactio: jeremy keith





















































adactio










journal
links
articles
notes
about













jeremy keith

making websites.
writing books.
hosting a podcast.
speaking at events.
living in brighton.
working at clearleft.
playing music.
taking photos.
answering email.




journal

3132
sparkline



links

10524
sparkline



articles

85
sparkline



notes

7697
sparkline



monday, february 17th, 2025




trot



working on this project is great but ten minutes into it and i already miss the resilience of the web. i miss how you have to really fuck things up to make a browser yell at you or implode.










1:36pm




tagged with
native
mobile
app
development
swift
ios
xcode
browsers
web
coding
code
programming
resilience







the imperfectionist: seventy per cent



if you’re roughly 70% happy with a piece of writing you’ve produced, you should publish it.

works for me!

you’re also expanding your ability to act in the presence of feelings of displeasure, worry and uncertainty, so that you can take more actions, and more ambitious actions, later on.
crucially, you’ll also be creating a body of evidence to prove to yourself that when you move forward at 70%, the sky stubbornly fails to fall in. people don’t heap scorn on you or punish you.










1:33pm




tagged with
70%
seventy
percent
rule
creativity
perfectionist
writing
publishing
creating
producting
output
standards





the hate of men will pass, and dictators die, and the power they took from the people will return to the people. and so long as men die, liberty will never perish.
— charlie chaplin, the great dictator









10:45am




also on
mastodon
bluesky



sunday, february 16th, 2025




my life in weeks by gina trapani


this is one way of putting things into perspective.









6:16pm




tagged with
weeks
life
timeline
dataviz
data
visualisation
events







the hardest working font in manhattan – aresluna


this is absolutely wonderful!
there’s deep dives and then there’s marcin’s deeeeeeep dives. sit back and enjoy this wholesome detective work, all beautifully presented with lovely interactive elements.
this is what the web is for!









6:13pm




tagged with
gorton
font
type
typography
lettering
mechanical
letters
lettershapes
graphic
design
cities
machines
interactive
explainer
keyboards
signs
signage
history



saturday, february 15th, 2025






saturday morning band practice.










3:32pm




also on
mastodon
bluesky
instagram



friday, february 14th, 2025




the tyranny of now — the new atlantis


i’m not a fan of nicholas carr and his moral panics, but this is an excellent dive into some historical media theory.

what innis saw is that some media are particularly good at transporting information across space, while others are particularly good at transporting it through time. some are space-biased while others are time-biased. each medium’s temporal or spatial emphasis stems from its material qualities. time-biased media tend to be heavy and durable. they last a long time, but they are not easy to move around. think of a gravestone carved out of granite or marble. its message can remain legible for centuries, but only those who visit the cemetery are able to read it. space-biased media tend to be lightweight and portable. they’re easy to carry, but they decay or degrade quickly. think of a newspaper printed on cheap, thin stock. it can be distributed in the morning to a large, widely dispersed readership, but by evening it’s in the trash.










5:46pm




tagged with
media
theory
history
innis
time
space
networks
durability
longevity
reach
control







ai is stifling tech adoption | vale.rocks


want to use all those great features that have been in landing in browsers over the past year or two? view transitions! scroll-driven animations! so much more!
well, your coding co-pilot is not going to going to be of any help.

large language models, especially those on the scale of many of the most accessible, popular hosted options, take humongous datasets and long periods to train. by the time everything has been scraped and a dataset has been built, the set is on some level already obsolete. then, before a model can reach the hands of consumers, time must be taken to train and evaluate it, and then even more to finally deploy it.
once it has finally released, it usually remains stagnant in terms of having its knowledge updated. this creates an ai knowledge gap. a period between the present and ai’s training cutoff. this gap creates a time between when a new technology emerges and when ai systems can effectively support user needs regarding its adoption, meaning that models will not be able to service users requesting assistance with new technologies, thus disincentivising their use.

so we get this instead:

i’ve anecdotally noticed that many ai tools have a ‘preference’ for react and tailwind when asked to tackle a web-based task, or even to create any app involving an interface at all.










5:40pm




tagged with
ai
machinelearning
language
models
tools
technology
generative
code
coding
frameworks
libraries
frontend
development
javascript
react
tailwind
anthropic
claude
gemini
chatgpt






reason



a couple of days ago i linked to a post by robin sloan called is it okay?, saying:

robin takes a fair and balanced look at the ethics of using large language models.

that’s how it came across to me: fair and balanced.
robin’s central question is whether the current crop of large language models might one day lead to life-saving super-science, in which case, doesn’t that outweigh the damage they’re doing to our collective culture?
baldur wrote a response entitled knowledge tech that’s subtly wrong is more dangerous than tech that’s obviously wrong. (or, where i disagree with robin sloan).
baldur pointed out that one side of the scale that robin is attempting to balance is based on pure science fiction:

there is no path from language modelling to super-science.

robin responded pointing out that some things that we currently have would have seemed like science fiction a few years ago, right?
well, no. baldur debunks that in a post called now i’m disappointed.
(by the way, can i just point out how great it is to see a blog-to-blog conversation like this, regardless of how much they might be in disagreement.)
baldur kept bringing the receipts. that’s when it struck me that robin’s stance is largely based on vibes, whereas baldur’s viewpoint is informed by facts on the ground.
in a way, they’ve got something in common. they’re both advocating for an interpretation of the precautionary principle, just from completely opposite ends.
robin’s stance is that if these tools one day yield amazing scientific breakthroughs then that’s reason enough to use them today. it’s uncomfortably close to the reasoning of the effective accelerationist nutjobs, but in a much milder form.
baldur’s stance is that because of the present harms being inflicted by current large language models, we should be slamming on the brakes. if anything, the harms are going to multiply, not magically reduce.
i have to say, robin’s stance doesn’t look nearly as fair and balanced as i initially thought. i’m on team baldur.
michelle also weighs in, pointing out the flaw in robin’s thinking:

ai isn’t llms. or not just llms. it’s plausible that ai (or more accurately, machine learning) could be a useful scientific tool, particularly when it comes to making sense of large datasets in a way no human could with any kind of accuracy, and many people are already deploying it for such purposes. this isn’t entirely without risk (i’ll save that debate for another time), but in my opinion could feasibly constitute a legitimate application of ai.
llms are not this.

in other words, we’ve got a language collision:

we call them “ai”, we look at how much they can do today, and we draw a straight line to what we know of “ai” in our science fiction.
this ridiculous situation could’ve been avoided if we had settled on a more accurate buzzword like “applied statistics” instead of “ai”.

there’s one other flaw in robin’s reasoning. i don’t think it follows that future improvements warrant present use. quite the opposite:

the logic is completely backwards! if large language models are going to improve their ethical shortcomings (which is debatable, but let’s be generous), then that’s all the more reason to avoid using the current crop of egregiously damaging tools.
you don’t get companies to change their behaviour by rewarding them for it. if you really want better behaviour from the purveyors of generative tools, you should be boycotting the current offerings.

anyway, this back-and-forth between robin and baldur (and michelle) was interesting. but it all pales in comparison to the truth bomb that miriam dropped in her post tech continues to be political:

when eugenics-obsessed billionaires try to sell me a new toy, i don’t ask how many keystrokes it will save me at work. it’s impossible for me to discuss the utility of a thing when i fundamentally disagree with the purpose of it.

boom!

maybe we should consider the beliefs and assumptions that have been built into a technology before we embrace it? but we often prefer to treat each new toy as as an abstract and unmotivated opportunity. if only the good people like ourselves would get involved early, we can surely teach everyone else to use it ethically!

you know what? i could quote every single line. just go read the whole thing. please.









5:07pm




tagged with
ai
machinelearning
language
models
technology
ethics
politics
sci-fi
sciencefiction
precautionary
hype
fairness
blogs
blogging
personal
publishing







how indie devs and small teams can win in a tech downturn - the new stack


in which rich nails clearleft’s superpower:

“clearleft is a relatively small team, but we can achieve big results because we are nimble and extremely experienced. as strategic design partners, we have a privileged position where we can work around a large company’s politics,” rutter said. “we need to understand those politics — and help the client staff navigate them — but we don’t need to be bound by them. we bring a thoroughly user-centered approach to our design partnership, and that can be something novel to companies. by showing them what good design looks like (not so much the interface, as the actual process of getting to really well-designed products and services), we can be disruptive within the organization and leave them in a much better place.”










3:49pm




tagged with
clearleft
agency
business
work
indie
independent
agencies
clients
design
partners







tech continues to be political | miriam eric suzanne



being “in tech” in 2025 is depressing, and if i’m going to stick around, i need to remember why i’m here.

this. a million times, this.
i urge you to read what miriam has written here. she has articulated everything i’ve been feeling.

i don’t know how to participate in a community that so eagerly brushes aside the active and intentional/foundational harms of a technology. in return for what? faster copypasta? automation tools being rebranded as an “agentic” web? assurance that we won’t be left behind?










11:11am




tagged with
ai
machinelearning
language
models
generative
tools
technology
society
ethics
politics



thursday, february 13th, 2025






thursday session 










9:18pm




also on
mastodon
bluesky







putting the ink into design thinking | clearleft


the power of prototyping:

most of my work is a set of disposables rather than deliverables, and i celebrate this.

i like the three questions that chris asks himself:


what’s the quickest, cheapest thing i can create to help make the next design decision?
what can i create to best demonstrate the essence of the concept?
how can i most effectively share the thinking behind the design with decision-makers? 











9:43am




tagged with
prototypes
prototyping
design
fidelity
process
thinking
making
decisions
clearleft







we live like royalty and don’t know it — the new atlantis


strong deb chachra vibes in this ongoing series by charles c. mann:

he great european cathedrals were built over generations by thousands of people and sustained entire communities. similarly, the electric grid, the public-water supply, the food-distribution network, and the public-health system took the collective labor of thousands of people over many decades. they are the cathedrals of our secular era. they are high among the great accomplishments of our civilization. but they don’t inspire bestselling novels or blockbuster films. no poets celebrate the sewage treatment plants that prevent them from dying of dysentery. like almost everyone else, they rarely note the existence of the systems around them, let alone understand how they work.










9:11am




tagged with
infrastructure
systems
society
history
luxury
education
ignorance



wednesday, february 12th, 2025




ai wants to rule the world, but it can’t handle dairy.



ai has the same problem that i saw ten year ago at ibm. and remember that ibm has been at this ai game for a very long time. much longer than openai or any of the new kids on the block. all of the shit we’re seeing today? anyone who worked on or near watson saw or experienced the same problems long ago.










4:51pm




tagged with
ai
machinelearning
language
models
ibm
watson
machinelearning
technology
change
business
digital
transformation





reading the heart in winter by kevin barry.










8:37am




also on
bookshop
open library







why is everything binary? (webbed briefs)


heydon’s latest video is particularly good:

all of my videos are black and white, but especially this one.










8:16am




tagged with
webbedbriefs
video
explainer
binary
thinking
psychology
society







what happens to what we’ve already created? - the history of the web



we wonder often if what is created by ai has any value, and at what cost to artists and creators. these are important considerations. but we need to also wonder what ai is taking from what has already been created.










8:09am




tagged with
ai
machinelearning
language
models
generative
content
art
history
slop







is it okay?


robin takes a fair and balanced look at the ethics of using large language models.









8:08am




tagged with
ai
machinelearning
language
models
tools
technology
generative
fairness
copyright
ethics



monday, february 10th, 2025

















sand










10:02pm




also on
mastodon
bluesky
instagram



older »





about this site

adactio is the online home of jeremy keith, a web developer and author living and working in brighton, england.

get in touch


customise


choose a theme…

default
dark
tatemodern
seaside
zeldman
adactizilla
sci-fi
renaissance
hirnlego


?


this is the plain vanilla look.


search


find

go!


within

adactio.com
journal
links
articles
notes




peruse the archive
browse the tags



subscribe
i have some feeds that you can subscribe to in your rss reader:

my journal
my links
my articles
my notes
my journal, links, articles and notes together



current location



projects
books i’ve written that you can read for free online:


html5 for web designers
published by a book apart in 2010


resilient web design
self-published in 2016


going offline
published by a book apart in 2018


websites i’ve built:


the session
an online community dedicated to irish traditional music.


huffduffer
create your own podcast feed of found sounds.


one-page websites:


a few notes on the culture
a 1994 newsgroup post by iain m banks.


the gęsiówka story
a little known page of jewish fighting history. by edward kossoy.


design principles
a collection of design principles from elsewhere, gathered into one place.


brighton sf
a panel discussion i hosted with brian aldiss, lauren beukes, and jeff noon.




elsewhere
you can find me scattered across these sites:

podcasting on huffduffer
updating mastodon
side-eying bluesky
syndicating to micro.blog
snapping on instagram
coding on github
reading on bookshop
buying on bandcamp
collecting on tumblr
experimenting on codepen
teasing on dribbble
learning on duolingo
putting pictures on flickr
posting to medium
speaking on notist
presenting on speakerdeck
watching on youtube
uploading to vimeo
drinking on untappd
loitering on facebook
perplexed by linkedin
documented on wikipedia



bedroll
i had the pleasure of welcoming these people into my home:


aaron gustafson


aaron parecki


amy guy


ben ward


brad frost


brian suda


cameron adams


cindy li


daniel boud


daniel burka


dan rubin


dave shea


derek featherstone


doug schepers


elizabeth galle


elsa kawai


emil björklund


erin jo richey


ethan marcotte


frances berriman


hannah donovan


indi young


james mcnally


jason santa maria


jenifer hanen


jina anne


joe clark


john morrison


jon linklater-johnson


lyza danger gardner


mandy brown


mark norman francis


matt harris


matthew somerville


natalie downe


nathan smith


patrick griffiths


petra gregorová


simon willison


stephanie hobson


tantek çelik


tim parkin






© 1998 - 2025 jeremy keith.

"". if no text was provided only use obscure words.





