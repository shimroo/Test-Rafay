




standblog





























































standblog
tristan nitot sur la technologie, l'internet et les libertés numériques


aller au contenu
aller au menu
aller à la recherche


homearchives







mercredi 12 février 2025
ia et consommation électrique


par tristan, 
mercredi 12 février 2025. 
technologie



“l’explosion de l’ia est inéluctable”, entend-on suite au sommet de l’ia à paris. sauf que…
quand on regarde la prévision de consommation électrique de l’ia (ici sur la base d’un récent document de deloitte global analysis), la consommation électrique des centres de données, sous la pression de l’ia, devrait faire un bond énorme pouvant être multiplié par un facteur 9,3 entre 2023 et 2050.
à coté de ce graphique[1], sur la droite, j’ai mis quelques coupures de presse qui démontrent bien que coté électrique, on a déjà pas mal de soucis : on redémarre en france une des deux centrales à charbon pour passer l’hiver sans pénurie. en irlande, ils font tourner les datacentres à coup de carburants fossiles pour pouvoir assurer la fourniture d’énergie. du coup, on n’a jamais autant brûlé d’énergies fossiles qu’en 2024. le gartner prévoit que 40% des centres données seront menacés de pénuries d’ici 2027. aussi, cela risque de retarder la transition énergétique. et bien sûr google et microsoft, on s’en souvient, voient leurs émissions de ges bondir à cause de l’ia.
mais on oublie quelque chose d’essentiel, c’est que pour réussir à prendre le virage climatique, il faut aussi électrifier l’industrie et aussi la mobilité (avec les fameuses voitures électriques).
alors, puisqu’il est si difficile de fabriquer des centrales électriques (combien de temps ça a pris pour l’epr de flamanville, déjà ?  17 ans, de quoi décidera-t-on de se passer ? de produits issus de l’industrie ? de voitures ? d’ia ?
sans compter que là, je vous parle d’énergie, mais ça veut dire que je passe sous silence les trois plus gros problèmes que sont les limites planétaires en général, l’effondrement de la biodiversité et le changement climatique[2].
ça m’amène à me poser la question suivante : un monde habitable n’est-il pas plus important qu’un ami imaginaire qui ferait une partie de mon boulot à ma place ?
notes
[1] ce graphique est tiré d’une conférence de 30 mn titrée l’humanité a-t-elle les moyens de s’offrir l’ia, présentée en décembre 2024 à open source expérience, à paris.
[2] je constate que je ne suis pas le seul à le dire, et c’est bien !






mardi 11 février 2025
en vrac de début février


par tristan, 
mardi 11 février 2025. 
en vrac


l’actualité est tellement dense ces derniers temps (et pas de façon positive) que je ne résiste pas à partager ces liens dès le 11 du mois.
ego trip
où je compile quelques liens vers des présentations / interventions / interviews pour en garder la trace :

l’humanité peut-elle s’offrir l’ia ?, une présentation de votre serviteur, où j’essaye de faire le rapprochement entre les possibilité impressionnantes de l’ia avec la difficulté de rester dans les limites planétaires. cette version-ci fut présentée à l’open source expérience en décembre 2024.
une conversation entre tristan nitot et jb piacentino sur l’histoire du numérique (url susceptible d’évoluer avec le temps). jb est un vieux complice, rencontré dans les années 1980 autour d’un apple ii, retrouvé dans les années 1990 alors que nous étions jeunes parents, nous avons ensuite travaillé ensemble chez mozilla, qwant et unsearch. maintenant chez clever cloud, il m’a invité pour refaire l’histoire du numérique, et c’était vraiment sympa !
un billet d’un spécialiste de l’histoire du numérique qui reflète bien ce que j’ai pu vivre.  the pc is dead: it’s time to make computing personal again. « dans les années 80 et 90, les geeks avaient l’impression de rendre le monde meilleur ». c’était indéniablement mon cas. mais quand voit la merdification des plateformes, l’emprise des multinationales sur nos cerveaux (et notre travail) et l’impact environnemental du numérique, on se dit qu’il faut réinventer tout ce bazar. avec des standards ouverts, du logiciel libre, du matériel réparable, de la décentralisation, de la bidouillabilité et du respect de l’utilisateur ;
sur linkedin, je regarde l’affaire deepseek comme une opportunité de frugalité pour l’ia et m’interroge sur l’effet rebond. et justement, la société asml voit les bas coûts de deepseek comme « une bonne nouvelle » pour ses affaires : « toute réduction des coûts est une bonne nouvelle pour asml, car une réduction des coûts signifie que l’ia peut être utilisée dans un plus grand nombre d’applications. plus d’applications signifie plus de puces » ;
votre serviteur sur bfm business ;

ia

deepseek might not be such good news for energy after all “new figures show that if the model’s energy-intensive “chain of thought” reasoning gets added to everything, the promise of efficiency gets murky.” ;
o3-mini and the environmental rebound effect of reasoning models,
l’ami rémy marrone lance ia frugale, une compilation de ressources sur le sujet.
luc julia discute de la frugalité pour l’ia ;
l’ia générative sera-t-elle l’excel de la société de la connaissance ? ;
l’humanité peut-elle s’offrir l’ia ?, où votre serviteur explique en quoi l’explosion de l’ia pose un problème à l’humanité d’un point de vue des limites planétaires. on notera que j’esquive les problèmes sociétaux directement, vu le peu de temps disponible.
il paraît qu’on n’arrête pas le progrès, mais parfois, j’aimerais que ça soit possible : ai is spamming open source repos with fake issues (une ia crée de faux rapports de bugs qui inondent des projets de logiciels libres, mais on n’a toujours pas compris pourquoi ) ;
o3-mini and the environmental rebound effect of reasoning models, ou comment deepseek, qui est bon marché, provoque un effet rebond. l’auteur de l’article en a une version française sur linkedin (désolé). en gros, l’approche chain of thoughts, qui permet d’avoir un raisonnement par l’ia et donc des résultats de meilleure qualité coûtent très cher en calcul. et donc, généraliser cette approche, certes désirable, provoque un effet rebond majeur, comme le démontre cet article du mit technology review ;
meta accusée d’avoir téléchargé plus de 81,7 to de livres piratés pour entraîner son ia. “des courriels montrent qu’elle a tenté de le dissimuler en évitant les serveurs de facebook lors du téléchargement”. c’est un problème de fond de l’ia (en plus de son empreinte environnementale et tous les dégâts qu’elle va faire dans la société) : les grandes entreprises qui font de l’ia l’ont entraînée sur des données pour lesquelles ils n’avaient pas les droits. et donc chacun, utilisant l’ia, a recours à un sous-produit illégal. cela finira-t-il par faire un scandale ou pas ? peut-être que non, l’ia étant “too big to fail”, elle aussi, comme les banques ?
les sacrifiés de l’ia, documentaire de l’excellent henri poulain
grosse enquête de next.ink : plus de 1 000 médias en français, générés par ia, polluent le web (et google). pire google semble s’en ficher…


mathieu chartier, journaliste victime de plagiat ia ;
une extension chrome et firefox pour être alerté des sites genai ;
news.dayfr, le site genai qui plagie 6 000 articles/jour ;
le papier de libé : faux rédacteurs, vrais profits : comment l’intelligence artificielle parasite l’info (réservé aux abonnés). extrait : “pour un euro, un éditeur de site peut acheter un article de 900 mots, enrichi d’une image d’illustration générée par ia, optimisée pour le référencement. de quoi réduire les coûts «par 200, au bas mot» par rapport à un pigiste de presse écrite.” ;
autre volet de l’enquête, toujours chez libé : photos hallucinatoires et rédacteurs virtuels : «news of marseille», le site touristique à la sauce ia ;
remplacées par chatgpt, les «petites mains» africaines du web voient fondre leurs revenus ;


pendant ce temps là, aux états unis

pour louer le travail d’elon musk, le président (trump) a brandi un exemple de dépense indue, inventée de toutes pièces : « cent millions de dollars de préservatifs pour le hamas. » sauf que non ;
l’administration trump aurait utilisé des ia pour écrire ses textes de loi, avec le souci que plusieurs sections portent le même numéro, ce qui rendrait difficile la mise à jour et la référence à ces textes ;
l’amérique en 2025, une vidéo générée par ia par les dor brothers, coutumiers du fait. c’est violent et très triste. c’est artificiel, mais très vrai de la vérité crue. à ne regarder que si vous avez le moral au beau fixe ! la chanson de fond est clint eastwood, de gorillaz ;
zuckerberg s’aplatit devant trump et verse 25 millions de dollars pour avoir osé fermer son compte facebook suite à l’attaque du capitole par ses électeurs fanatisés le 6 janvier 2021. il achève ainsi la transformation de son entreprise, initialement progressive en soutien du maga de trump. comme quoi on peut être fan de mma et ne pas avoir de colonne vertébrale !
don’t believe him, où le journaliste ezra klein explique ce qui est d’après lui la stratégie de trump : balancer chaque jour trois énormités qui inondent les médias (mainstream et sociaux) par son aspect explosif, qui mobilise toute leur attention et passer en force, jour après jour.
dans la droite ligne du lien ci-dessus, je recommande vivement le travail de julien devaureix chez sismique. en particulier 2 épisodes sur les usa et ce qu’ils vivent :


la nouvelle ère de la puissance brutale (daté du 15 janvier 2025, juste avant la prise de pouvoir de trump et musk) et
amérique 2025 : les architectes du chaos, en date du 7 février.

les données des centres de prévention des maladies américains sauvées via internet archive, les geeks au secours des données du gouvernement américain ;

totalement en vrac

obsolescence programmée : google pixel 4a : cas d’école de l’obsolescence programmée . “dans les prochains jours, votre pixel 4a sera automatiquement mis à jour (…). cette mise à jour réduira l’autonomie et les performances de recharge de votre batterie.” ;
l’association greenit vient de publier un nouveau rapport sur les impacts environnementaux du numérique dans le monde 2025. france info en parle : si le numérique était un pays, il émettrait autant de gaz à effet de serre que 5,5 fois la france ;
nouvel épisode dans le scandale des eaux minérales. fraude aux eaux minérales : comment l’elysée et matignon ont cédé au lobbying de nestlé malgré les alertes des autorités de santé. voir aussi l’article de france info : enquête scandale des eaux en bouteille : de l’élysée à matignon, révélations sur le lobbying de nestlé au sommet de l’etat  ;
envie de voir tous les mauvais cotés de l’ia ? pivot-to-ai.com est là pour ça !
et si la troisième guerre mondiale avait déjà commencé ?, par albin wagener. rien que le titre est décourageant, mais finalement, l’article est passionnant : guerres cognitive, environnementale, médiatique et enfin sociale.
windows 11 : quatre méthodes pour contourner tpm 2.0.







mercredi  5 février 2025
les problèmes sociétaux du déploiement massif de l'ia


par tristan, 
mercredi  5 février 2025. 
technologie


j’ai demandé à l’ia claude “quels sont les problèmes sociétaux posés par le déploiement de l’ia à l’échelle ?”. voici sa réponse (spoiler alert : elle a plié le game), je vous la copie-colle ici pour que vous n’ayez pas à la poser à nouveau. à cause, justement, de tous les problèmes que cela pose :

les principaux problèmes sociétaux posés par le déploiement massif de l’ia incluent :
1. inégalités économiques

automatisation massive de certains emplois
concentration des richesses dans les entreprises technologiques
risque de précarisation de larges segments de la population active

2. questions éthiques

biais algorithmiques reproduisant des discriminations
décisions automatisées sans responsabilité claire
atteintes potentielles à la vie privée
risques de manipulation psychologique

3. enjeux démocratiques

propagation facilitée de désinformations
influence des systèmes d’ia sur l’opinion publique
capacité de profilage et de surveillance massive
risque de réduction de l’autonomie individuelle

4. problèmes juridiques

cadre légal inadapté
difficultés d’attribution des responsabilités
problèmes de propriété intellectuelle
nouveaux types de crimes numériques

5. aspects environnementaux

consommation énergétique importante des datacenters
impact carbone de l’entraînement des modèles
extraction massive de ressources pour les infrastructures

ces défis nécessitent une régulation internationale et une réflexion éthique approfondie.

note : ce billet, par essence, a partiellement été généré par une ia, puisque l’idée était de citer l’ia en question. c’est une exception sur le standblog et cela a vocation à le rester.






mercredi 29 janvier 2025
en vrac de janvier


par tristan, 
mercredi 29 janvier 2025. 
en vrac



un web moins nul est-il possible ? internet exploreuses s02e04. une partie sur le design et le son impact commence à 50 minutes, avec l’interview de la chercheuse nolwenn maudet ;
interview de nate hagens (the great simplification), qui est un type super intéressant. économiste de formation, il a une approche systémique. parce qu’il voit dans l’énergie une partie importante du problème auquel on fait face, il est un peu jancoviciste, dans une certaine mesure, mais comme il est économiste et pas ingénieur, et qu’il a une pensée systémique, ça en fait quelqu’un de très intéressant. dans sa vidéo, je recommande tout particulièrement les parties sur la grande simplificationla résilience mentale, les recommandations pour les jeunes et le rôle de l’ia à l’avenir.
l’improbable pivot de tusimple, qui passe d’une entreprise fabriquant des camions sans chauffeurs à une boite qui fait de l’ia générative. cette boite a pivoté tellement que ça file le tournis !
portrait de david maenda kithoko, militant écologiste né au congo. une des personnes qui m’a le plus touché ces derniers temps. on regardera avec intérêt sa conférence pour une écologie décoloniale du numérique, présentée à la récente journée de l’écoconception numérique ;
amusant : la loi de moore (et sa fin) appliquées à la photographie numérique par sylvain lepoutre. le passage intéressant commence à 7:37 ;
tests unitaires, une philosophie et une aide face à son logiciel,
après avoir sorti un abonnement à 200$ par mois, openai se rend compte qu’ils perdent aussi de l’argent sur cet abonnement : les gens s’en servent à tort et à travers.. rappelons qu’à une époque, faire tourner chatgpt coûtait 700 000$ par jour rien qu’en électricité. openai s’attend à 5 milliards de dollars de pertes pour un chiffre d’affaire de 3,7 milliards de dollars  l’année dernière.
de wikipédia à openai, les communs numériques font de la résistance
l’open source, l’armée de l’ombre du logiciel… et de l’intelligence artificielle ;
microsoft is using bing to trick people into thinking they’re on google
créer des jeux avec du vieux permacomputing : agriculture et jeu vidéo, même combat ?, avec des gens comme vincent moulinet, artiste, curateur et développeur ; everest pipkin, artiste du texas, autrice du drift mine satellite ; florent deloison ; chloé desmoineaux, artiste, queer et créateurice du fluidspace ; nikita semenoff, artiste, développeur de jeux vidéos ;
resurrecting the minimalistic dillo web browser “to force ourselves to keep the browser small and simple, the next releases will continue to fit inside a floppy disk (1.44 mb)” <3
living on mars would probably suck — here’s why, une interview de deux auteurs du livre “a city on mars”

empreinte du numérique

l’ademe publie une mise à jour de son evaluation de l’impact environnemental du numérique en france. “cette étude vise à mettre à jour les données de l’étude menée avec l’arcep en 2020 sur l’évaluation de l’impact environnemental du numérique en france, aujourd’hui et demain. en effet, n’avait été pris en compte dans les hypothèses de l’étude de 2020, que les data centers situés sur le territoire français. or une partie importante des usages en france sont hébergés à l’étranger (environ 53 %) ce qui représente des impacts très loin d’être négligeables. par ailleurs, entre 2020 et 2022, le mix entre les télévisions oled et lcd-led a varié au profit des télévisions oled plus grandes et plus impactantes ainsi que les usages notamment due à l’arrivée massive de l’ia.” (mais qui aurait pu prévoir, comme disait l’autre ?) ;
à la question fréquemment posée : “combien d’électricité vont utiliser les datacentres ?”, brian o’kelley répond : “according to lawrence berkeley national laboratory, in 2023, data centers consumed 4.4% of us electricity. driven by demand for generative ai, data centers may consume as much as 12% by 2028, more than the electricity used by california, florida, and new jersey combined.” dans un contexte plus européen : “the projected data center electricity use in 2028 would be enough to power germany” d’après l’iae ;
hype, sustainability, and the price of the bigger-is-better paradigm in ai, un papier scientifique (encore un avec la participation de l’excellente sasha luccioni et de gaël varoquaux, ) sur le fait qu’un modèle de llm avec plus de paramètre consomme plus, mais n’est pas forcément mieux. au risque de susciter des pensées malvenues, “plus gros n’est pas forcément mieux” (oui, ça s’applique aussi à la taille des bagnoles !). le papier évoque aussi la loi de wirth (aka “ce qu’intel vous donne, microsoft vous le reprend” dans les années 2000) et explique que maintenant, en substance, “ce que nvidia vous vend, les llm vous le reprenne”, en consommant sans cesse plus de ressources numériques. on n’a pas l’arrière-train sorti des ronces !
microsoft won’t support office apps on windows 10 after october 14th microsoft annonce que “refreshing an old windows 10 pc will be more important than buying a new tv or phone this year”. je hurle d’entendre ce mot “rafraîchir” qui signifie en fait “jeter à la benne (ou passer sous gnu/linux) un ordinateur qui fonctionne très bien juste parce que ça arrange microsoft et les vendeurs de pc”.
l’ia devrait doubler sa consommation d’électricité dans les 5 années à venir, explique deloitte. next détaille en français et montre que ça devrait se faire principalement à partir de gaz naturel;
generative ai – the power and the glory, un très long article sur l’ia, l’énergie nécessaire pour la faire tourner, et son futur. dans sa phrase “which wins: koomey’s law or the jevons effect?”, j’aime l’opposition entre loi de koomey (la consommation d’énergie pour faire 1 opération informatique diminue au même rythme que la loi de moore) et paradoxe de jevons (moins ça coûte cher, plus on en fait), en se demandant qui va gagner. simon willison en a fait un très bon résumé ;
article de juillet 2024 par nvidia : how ai and accelerated computing are driving energy efficiency où la firme explique avoir optimisé d’un facteur 45 000 sur 8 ans l’efficacité énergétique de ses puces, via ce graphe : llm inference energy consumption plummeted 45,000x in eight years, thanks to advances in nvidia gpus. . l’article ajoute qu’il y aurait un gain d’efficacité énergétique d’un facteur 25 entre les puces nvidia hopper (2022) et blackwell (2024) lors d’inférence ia. une question me taraude : dans quelles proportions ont augmenté les ventes de gpu nvidia sur la même période ? rien d’illogique à cela, ça s’appelle le paradoxe de jevons ;
l’ia o3 d’openai vient d’obtenir un score incroyable au test arc-agi-1  en réussissant 87,5% des tests. rappelons que gpt-3, en 2020, avait 0% de bonne réponses, gpt-4o obtenait  5% en 2024. et là, on passe à 87,5% de bonnes réponses ! deux points importants toutefois :


certains exercices sont triviaux pour des humains, mais l’ia se plante complètement alors qu’elle réussit des tests très similaires.
le coût des ressources mobilisées pour passer le test sont astronomiques : environ 350 000$ si mes calculs sont exacts, vu le prix des puces, des infrastructures et de l’énergie consommée pour faire tourner l’ia le temps du test. sur la fin de l’article, on voit quels problèmes ne peuvent pas être résolus par l’ia, alors qu’un collégien y arriverait probablement.

le site ourworldindata est une source très riche de données en tous genres. je viens de découvrir (merci maxime !) un graphe des données d’entrainement de modèles d’ia, qui donne un peu le vertige. comparons un gros modèle de juin 2009, gpu dbns et un autre gros modèle, grok 2, d’août 2024. le second a nécessité 53 milliards de fois plus de puissance de calcul que le premier, à 15 ans de différence.
dans le même genre, on constate que les coûts de calcul pour et donc de recherche sur l’ia augmentent tellement vite que seuls les industriels peuvent faire de la recherche, parfois en partenariat avec le monde académique. auparavant, les labos universitaires menaient seuls la recherche en ia, mais l’explosion des coûts de calculs pour entraîner un modèle ont changé les choses.
sasha luccioni - ia et crise climatique : prêts pour le choc ? dans trenchtech s04e02 est un vrai bonheur !
magnifique citation d’un analyste de morgan stanley research : “we think the huge step up in energy needs is not well understood by the market and hasn’t been priced into a number of stocks.” en français : “nous pensons que l’augmentation brutale des besoins énergétiques n’a pas été bien comprise par la marché et n’a pas été prise en compte dans le prix d’un certain nombre d’actions”. comprendre : quand on va réaliser ce que ça coûte vraiment, les gens vont reconsidérer leur usage de l’ia. et encore, il ne parle que de prix de l’énergie, pas du coût environnemental ! on notera que l’article date de mars 2024, mais reste d’actualité, plus encore même aujourd’hui !
l’ami simon willison a publié un article llms in 2024, un récapitulatif de ce qu’il a appris en 2024 sur l’ia et les llm. il y a deux sections particulièrement intéressantes : the environmental impact got better (gros progrès sur l’optimisation des llm, c’est bien) et l’impact environnemental a beaucoup empiré (on construit et prévoit de construire beaucoup plus d’infrastructures numériques pour accompagner l’hypercroissance de l’ia, bref, on optimise et ça fait un méga effet rebond). mais c’est beaucoup vu sous deux angles classiques des techno-solutionnistes : “c’est un problème de capital” / “c’est un problème d’énergie”. mais le problème est bien plus large à mon sens : c’est un problème de limites planétaires. du coup j’ai fait un article en anglais qui est une traduction d’un billet linkedin en français ;

mobilité

« mon seul regret ? ne pas avoir commencé le vélo plus tôt » : récit d’une transition vélo réussie,  une interview de votre serviteur par la magazine weelz. ma carrière d’influenceur vélo commence. modestement, mais elle commence !
elon musk is sending doge after high-speed rail ;

merdification

vers un internet plein de vide ?, sur l’ai slop, d’hubert guillaud ;
apple reconnait que siri a enregistré des conversations sans consentement et “a accepté de payer 95 millions de dollars pour sceller une action en justice” ;
‘j’ai adoré twitter et détesté ce que c’est devenu’ explique tristan nitot ; une interview de votre serviteur par le journaliste belge damien van achter. avec des vrais morceaux de gros mots dedans.
spotify, la machine à humeur, une plongée fascinante dans le business model de spotify, par le toujours excellent hubert guillaud. voir aussi « pour les dirigeants de spotify, l’utilisateur moyen de la plateforme ne remarquera pas si les chansons sont produites par de faux artistes » ;
ia : le coup de gueule de paul mccartney. d’un coté, je suis d’accord : l’ia des milliardaires pille les contenus sous copyright alors que les ayants-droits traînent en justice les amateurs de musique. mais je trouve l’argument de mccartney un peu faible. finalement, c’est plus la conclusion de l’article qui m’interpelle : “deezer, la plateforme de streaming française, a ainsi décidé d’exclure les contenus générés par l’ia. « nos équipes ont développé en interne, pendant un an, un outil qui permet de détecter les morceaux créés par l’intelligence artificielle », - soit un titre sur dix envoyé chaque jour sur deezer -, a indiqué dans la tribune dimanche, ce dimanche, alexis lanternier, son directeur général.”
je lis occasionnellement ed zitron, mais là, je me retrouve vraiment dans ses propos (sauf que lui explique les choses mieux que moi).  la forme est amusante au début, fatigante à la fin, mais vise presque toujours juste. deux exemples, publiés de décembre dernier :


l’emmerdification de la technologie , sur le thème lancé par cory doctorow ;
godot ne viendra pas, sur l’ia.

meta abandons fact-checking on facebook and instagram in favor of community notes. au passage les modérateurs de meta sont délocalisés de californie (démocrate) au texas, état très conservateur : zuckerberg says he’s moving meta moderators to texas because california seems too ‘biased’. les conséquences ne tardent pas : meta now lets users say gay and trans people have ‘mental illness’ ;

complètement en vrac

je suis assez fan de nate haggens, découvert via le podcast sismique. je vient d’écouter sa présentation les 9 traits de caractère historiques qui desservent l’humanité, dans le cadre de son travail the great simplification, “a podcast that explores the systems science underpinning the human predicament. conversation topics will span human behavior, monetary/economic systems, energy, ecology, geopolitics and the environment. the goal of the show is to inform more humans about the path ahead and inspire people to play a role in our collective future”. on regardera avec intérêt sa vidéo 7 philosophies on the future ;
les deux articles du monde sur la pollution aux pfas sont fascinants :


excaver les sols, changer l’eau des lacs, ne pas jouer dehors : la pollution aux pfas plonge la flandre dans un désastre dystopique ;
100 milliards d’euros par an. c’est la facture vertigineuse que les européens devront payer pour éliminer les pfas de leur environnement.

de l’agi à la super-intelligence : openai redéfinit ses ambitions. un article qui laisse un drôle de goût dans la bouche. d’un coté, l’intelligence artificielle générale (iag, une ia aussi intelligente que l’humain) serait à portée de main, grâce à des progrès du modèle o3 d’openai. de l’autre, une utilisation hallucinante d’énergie : “un coût d’exécution total du test dépassant largement plusieurs centaines de milliers de dollars” alors que… “o3 échoue encore sur des tests triviaux pour les humains”.
‘i spent 30 years searching for secret to happiness - the answer isn’t what i thought’. je tombe “pasr hasard” sur cet article alors que je repensais le matin même, à vélo, à la prière de la sérénité, me disant qu’il fallait que je la publie sur le standblog. sauf que je l’ai déjà fait il y a déjà 9 ans : deux astuces pour rester serein ;
salut nazi et conquête de mars, une interview d’irénée régnault par reporterre ;
bishop mariann edgar budde appeals to president trump to have mercy upon immigrants and minorities. la femme évèque mariann edgar budde, dans son sermon, explique au président trump, présent, que dieu s’attend à ce qu’il fasse preuve de pitié envers les migrants et les minorités.  ;







jeudi 23 janvier 2025
la merdification de twitter et des plateformes en général


par tristan, 
jeudi 23 janvier 2025. 
technologie


les gens quittent twitter/x parce que c’est devenu un feu de poubelle. un algo toxique, truqué par son nouveau propriétaire en sa faveur. des scandales à répétition, des insultes envers les annonceurs, des propos nauséabonds en rafale, du racisme, de l’homophobie, de la transphobie, une modération qui part en quenouille et cerise sur le gâteau, des saluts nazis (ou mussoliniens).
pas étonnant que les gens partent en nombre. pour ma part, j’ai dit adieu à mes 96 000 followers il y a presque 18 mois avec soulagement. depuis, twitter/x n’a fait que dévisser dans l’estime des gens.
musk récolte ce qu’il a semé. soit.
au delà des provocations de musk
mais il y a un contexte moins connu qui touche la plupart des plateformes, c’est la notion de merdification / emmerdification / enshittification théorisée par l’excellent cory doctorow et déjà abordée dans ces pages.
la merdification est une dégradation de la qualité qui affecte les plateformes numériques qui opèrent sur un marché biface, par exemple celles qui mobilisent à la fois des utilisateurs et des annonceurs.
elle opère en 4 étapes :

les plateformes servent les intérêts de leurs utilisateurs, qui en deviennent dépendants. elles fournissent un produit ou service utile à perte. les utilisateurs affluent, recommandent la plateforme, font venir d’autres utilisateurs
les plateformes utilisent ces utilisateurs pour servir les intérêts de leurs entreprises clientes, à perte. la plateforme se met à privilégier le coté entreprises de son marché. l’expérience des utilisateurs se dégrade (plus de pub, moins de respect de la vie privée), celle des entreprises s’améliore. d’autres entreprises affluent.
les plateformes profitent de ces deux catégories de clients, devenus captifs, pour servir leurs propres intérêts : les surplus sont distribués aux actionnaires. dans cette phase, les entreprises merdifiées n’ont plus aucune raison de proposer un service de bonne qualité : elles sont incontournables autant pour les utilisateurs que les entreprises, avec un coût de sortie élevé pour les deux côtés.
les plateformes finissent par mourir quand les utilisateurs trouvent une alternative à la plateforme et que les entreprises se tournent à leur tour vers d’autres plateformes.

ce phénomène est un classique des plateformes. comme tous les modèles, il n’est pas parfait, mais il permet de comprendre plus facilement le cycle de vie des plateformes.
où en est votre plateforme préférée ?

les plateformes les plus anciennes comme myspace, aol messenger, icq sont en phase 4, c’est à dire mortes ou zombifiées.
amazon est en phase 3 sur le e-commerce, incontournable pour les utilisateurs comme pour les fournisseurs, mais qui voient leurs marges fondre comme beurre au soleil car ils sont obligés de commander de la publicité pour arriver à vendre. forcément, ça fait monter les prix et c’est une moins bonne affaire qu’avant pour les individus.
l’offre vidéo amazon prime est pour sa part en phase 2.  les pubs se multiplient, maintenant qu’ils ont réussi à convaincre les individus).
bluesky, probable remplacement de twitter, est en phase 1, encore séduisant, mais pour combien de temps ?
mastodon, me demanderez-vous, n’est pas concerné, n’étant pas commercial, sans algorithme de recommandation et sans publicité. mise à jour : mastodon n’est pas un réseau social. tout s’explique !







mardi 21 janvier 2025
pourquoi il faut quitter x


par tristan, 
mardi 21 janvier 2025. 
politique


pourquoi ça ne servait à rien de rester sur x en espérant faire pencher la balance du “bon coté” ?

l’algorithme de recommandation favorise les discours clivants
la taille des message favorisant pour sa part les messages courts donc simples.
loi de brandolini : il est 10 fois plus facile et rapide de dire une connerie simple et méchante que de la débunker. donc dire quelque chose d’intelligent et complexe sur x.com passe totalement inaperçu. (combinaison des 3 premiers points).
elon musk a fait modifier l’algorithme de twitter/x pour rendre ses messages et ses idées beaucoup plus visibles de tout le monde.

quand on combine tout ça, on voit comment les idées simplistes, agressives et nauséabondes se répandent mécaniquement au dépens des idées plus subtiles et plus nuancées.
alors on peut toujours s’épuiser à tenter de corriger cela, mais c’est futile : le propriétaire de la plateforme en a décidé autrement. d’où mon départ il y a presque 18 mois, malgré mes 96 000 followers là-bas. depuis, je suis sur linkedin mastodon et bluesky. voir aussi ma vidéo chez damien van achter, où je reviens sur le sujet.
mise à jour : tiens, un mème fort à propos :






jeudi 16 janvier 2025
the issue with ai


par tristan, 
jeudi 16 janvier 2025. 
en


a few weeks ago, someone on linkedin wrote “with ai, the sky is the limit”. i respectfully disagree.
i agree that ai is amazing. its possibilities seem limitless. but ai does not exist in a vacuum. it exists on our planet. the said planet has boundaries. scientists have assessed 9 planetary boundaries, 6 of them are crossed.

using and developing ai is an issue for 5 of these boundaries:

climate change. to power ai data-centers, we need energy, which often comes from burning fossil fuels. building data-centers also generates carbon emissions, along with building servers and gpus.
land-system change when pouring concrete to build data-centers, factories, power plants and roads to connect them together.
novel entities and pollution with chemicals when building all of this.
freshwater use when manufacturing silicon chips (tsmc consumes 100 million metric tons of water per year) and to cool down data-centers.
biodiversity integrity as a result of the factors above.

it’s a fact: our planet is in a bad shape and it’s been getting worse over time.
accelerating ai may sound exciting but it’s also is accelerating destruction of life. which is very annoying as i’m very impressed by ai, like many people!
we need to put our heads up and look at the pollution we’re creating. look at the quickly approaching wall.
so, what do we do: turn the wheel and slow down, or stay hypnotized by impressive gadgets?
keep playing with chatgpt or look a the los angeles megafires?





vendredi 20 décembre 2024
en vrac de décembre


par tristan, 
vendredi 20 décembre 2024. 
en vrac



sortie du raspberry pico 2 w à 8 €. c’est là qu’on voit que la puissance d’un ordinateur du début des années 1990 sous ms-dos vaut maintenant 8 € et mesure 21 mm x 51 mm et dispose en plus du wifi et du bluetooth ;
les propriétaires de tesla gênés par les frasques d’elon musk achètent des autocollants en masse . “je l’ai achetée avant qu’on ne découvre qu’il était cinglé” ou “club tesla anti-elon”.
‘enshittification’ nommé mot de l’année par un dictionnaire australien. mot inventé en 2022 par cory doctorow et désignant le fait que les plateformes massivement utilisées finissent après une période de succès auprès des citoyens par se solder auprès des marques pour augmenter leurs bénéfices avant enfin de trahir les marques pour maximiser encore plus les profits.
pourquoi les médias devraient créer des serveurs mastodon maintenant, par le responsable réseaux sociaux de médiapart (article en accès libre) ;
il faut respecter les limites de notre planète pour sauver nos démocraties expliquent dans une tribune plus d’une centaine de chercheurs qui veulent s’assurer que les lois à venir sont compatibles avec les limites planétaires. brillante idée !
modixia, une entreprise française qui produit des pc de bureau à partir de pc portables qu’ils reconditionnent. deux modèles : pc restart et pc infinity
101 millions de m3 d’eau par an, telle est la consommation annuelle du fabricant de semiconducteurs tsmc. cela a doublé par rapport à 6 ans plus tôt.
pour ceux qui font des présentations sur l’ia, au lieu de faire faire des bouses par midjourney ou dall-e (des ia génératives), voici des travaux humains sous licence cc-by betterimagesofai.org. c’est très inégal, mais j’ai bien aimé clickworker abyss by max gruber, gpu shot 3 models built from fossils et silicon closeup ;
il y a un coté jouissif à voir la différence entre ce qui nous est promis et ce qui nous est livré. par exemple, on entend souvent des entreprises dire “on va émettre du co2, mais c’est pas grâce, on va le capture de façon croissante, comme ça, on peut continuer comme avant”. bref, le discours du business as usual. et puis on tombe sur carbon capture, utilisation and storage, de l’agence internationale de l’énergie. on nous promet des capacités de capture du co2, avec quasiment autant de stockage du co2 capturé. et ça fait des années que ça dure. sauf que l’iae a comparé les promesses (sans cesse croissantes) à ce qui est actuellement opérationnel et tristement plat. ça serait drôle si ça n’était pas si triste !
microsoft now allows windows 11 installations on unsupported hardware, devices, but with several caveats. il y a encore une semaine, ils proclamaient que la puce tpm 2.0 était indispensable pour installer windows 11, et finalement non, comme l’explique la page de support ‘installer windows 11 sur des systèmes non supportés’. c’est tellement bizarre de voir microsoft osciller entre la position “moi vivant, jamais” et “vous savez bien qu’on est des gentils”. ca discrédite largement la parole de redmond, quand même. et changeront-ils encore d’avis pour exiger la présence de puce tpm 2.0 la semaine prochaine ou pas ? est-ce que le fait que la popularité de windows 10 remonte (si, si !) joue un rôle ? aux dernières nouvelles, windows 10 est à 62% et windows 11 à 35% ;
on me demande parfois si l’humanité va disparaitre avec le changement climatique et le franchissement des limites planétaires. je pense que non, et un article l’explique bien : quand seulement un millier d’humains peuplaient la terre. “98,7 % de nos ancêtres auraient été balayés par cet épisode, laissant à peine quelques centaines de génomes porter l’avenir de l’humanité. « le modèle a détecté une réduction de la taille de la population de nos ancêtres d’environ 100 000 à environ 1 000 individus », peut-on lire. par ailleurs, au-delà du nombre d’individus surprenamment bas, ce qui intrigue le plus est la durée de ce goulot d’étranglement. l’étude suggère que nos ancêtres ont réussi à survivre en nombre précairement réduit pendant une période extrêmement longue : environ 120 000 ans.” si 99% des terriens du xxie s. venaient à disparaître, ça ferait quand même pas loin de 8 à 10 milliards de morts prématurés. le moins qu’on puisse dire, c’est ça va faire une bonne dose de souffrance… comme le dit le militaire christophe mangeant, “si vis pacem, para transicum” (“si tu veux la paix, prépare la transition”).
d’ailleurs, je recommande sa présentation du modèle world 3 (limits to growth) des époux meadows (ça vous évitera la lecture de l’excellent les limites à la croissance) ;
j’étais sur bfm business pour le débrief de la tech du 16/12/2024 ;
à quel climat s’adapter en france selon la tracc ? partie 1 concepts et données de base pour les températures et précipitations ;
podcast geo : data centers de seine-saint-denis, les lourds impacts de nos données numériques ;
ethical web principles: building a better web par mon collègue du tag daniel appelquist ;
taïwan, histoires mêlées et futurs orageux de la numérisation, un article long et complet de l’excellent gauthier roussilhe ;
l’arcep et l’ademe annoncent la création de l’observatoire des impacts environnementaux du numérique ;
podcast l’ia est une nouvelle bombe climatique par les excellents lou welgryn et théo alves da costa de dataforgood ;






« billets précédents - 
				
		page 1 de 604		
			
 
 



le livre surveillance://


je suis l'auteur du livre surveillance://, les libertés au défi du numérique : comprendre et agir. 

nous générons chaque jour plus de données qui sont captées par des multinationales et des états, et cela peut se retourner contre nous. comment est-ce possible ? comment éviter cela ? ce sont les questions auxquelles je réponds dans ce livre, qu'on peut se procurer chez c & f éditions.


rechercher 





à propos de l'auteur
biographie
mon profil linkedin
mes photos sur flickr.com
mes dernières présentations



select your language français  english 


suivez moi !sur twitter : @nitotvia rss : 



sériesamazonclimatflicage-brouillongafamgrevemotovelovelotafzerotoutes les séries


catégoriesstandardsnavigateursaccessibilitépolitiquetechnologieen vracenmotoenvironnementphotographiebeyond-the-codelife hackingvieux trucsflicage-brouillonpodcast



 


quelques billets notables décès de niklaus wirth quelle est l'empreinte carbone d'un français moyen ? les 20 ans du standblog que dit le nouveau rapport du giec sur l'adaptation ? de combien va se réchauffer la planète d'ici à la fin du siècle ? numérique et climat : se focaliser sur ce qui est important comprendre le changement climatique en 10 minutes le bitcoin est-il écolo ? faut-il faire le ménage dans ses mails pour être écolo ? je lance un podcast : l'octet vert quelles sont les conséquences du changement climatique ? le changement climatique, ça change tout ! quand le changement climatique nous emmène vers le deuil imaginer un futur souhaitable au revoir, qwant ! bilan un an de velotaf le déni citation du jour : hanna arendt et l'importance de la vérité agir pour le climat à titre individuel en guise de vœux 2019 le naufrage moral de facebook mieux travailler en équipe avec l'alliance co-créée comprendre la colère des automobilistes face au prix de l'essence climat et environnement à nouveau sur le devant de la scène je rejoins qwant facebook sans boussole morale trump : la première leçon livre surveillance:// : premier bilan lancement de mon livre surveillance défendre le chiffrement 10 ans de firefox introduction à la bidouillabilité about generativity le logiciel et moi (4/4) : conclusion le logiciel et moi (3/4) : le logiciel libre, nouveau mode d'organisation le logiciel et moi (2/4) : de l'importance du logiciel et de sa liberté le logiciel et moi (1/4)  : le logiciel propriétaire l'homme (libre) qui plantait du code please don't use facebook to contact me la soupe au caillou ma chapelle mais qu'est-ce qui fait courir tristan ? 


incontournablesmozilla.org
openweb
opquast en français


 

 
haut de page

homearchives


 




s'abonner





à propos





contactez-moi



ce site, qui porte principalement sur les standards du web, les navigateurs et la technologie, est maintenu par tristan nitot.
les opinions exprimées sur ce site sont uniquement celles de son auteur et ne sauraient être attribuées à quelconque organisation à laquelle il pourrait être affilié.
ce site fonctionne avec des logiciels libres tels
que debian gnu/linux, apache, mysql, php et dotclear.

 


