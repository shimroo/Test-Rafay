





persci – perceptual science group @ mit











































perceptual science group @ mit


persci







peoplepublicationsresearchgallerycontact




search










faculty

edward adelson
ruth rosenholtz



research scientists

jennifer corbett



postdoctoral scholars

vasha dutell



graduate students

anne harrington
christian kovesdi



affiliates

benjamin balas
kimo johnson
aude oliva



administration

elmer cat



recent alumni

shayian keshvari
jianhua li
benjamin wolfe
siyuan dong
shaoxiong wang
dian yu
wenzhen yuan
zhendong zhang
bei xiao
krista ehinger
xuetao zhang
derya akkayanak
phillip isola
rui li

all alumni







the perceptual science group of the department of brain and cognitive sciences at mit does research in human vision, machine vision, human-computer interaction, and touch sensing for robotics. both the adelson lab and the rosenholtz lab are part of the computer science and artificial intelligence lab (csail), located in the stata center.





news…


benchmarking deep network and human performance in the periphery


anne harrington, vasha dutell, and ruth rosenholtz, with collaborators in bill freeman’s lab and toyota research have a new paper on a change detection paradigm to compare human and deep neural network object detection. 
object detection in deep neural networks differs from humans in the periphery



training object detection deep neural networks on mongrel images


anne harrington, vasha dutell, and ruth rosenholtz, with collaborators in bill freeman’s lab and toyota research have a new paper on using mongrels to evaluate and train deep neural networks. 
evaluating peripheral vision as an input transformation to understand object detection model behavior



learning statistics for peripheral and texture models


christian kovesdi, vasha dutell, anne harrington, and ruth rosenholtz, with collaborators in bill freeman’s lab demonstrate a method of learning model statistics. 
stattexnet: evaluating the importance of statistical parameters for pyramid-based texture and peripheral vision models



interpreting deep neural networks using temporal stability measures


anne harrington, vasha dutell, and ruth rosenholtz, with collaborators in bill freeman’s lab and toyota research institute have a new iclr paper on temporal stability in neural networks. 
exploring perceptual straightness in learned visual representations



creating mongrel images with gpu acceleration


vasha dutell and ruth rosenholtz, with collaborators at nvidia, report on a new method for creating mongrel images. 
efficient dataflow modeling of peripheral encoding in the human visual system



how we acquire information from dynamic scenes


benjamin wolfe and ruth rosenholtz have a new paper setting out their information acquisition theory in driving. 
toward a theory of visual information acquisition in driving



why vision works as well as it does, yet we are poor at the details


ruth rosenholtz has a new paper re-examining limited capacity and visual attention in light of work on peripheral vision from the last decade.
demystifying visual awareness: peripheral encoding plus limited decision complexity resolve the paradox of rich visual experience and curious perceptual failures



modeling peripheral vision


recent experimental work appears to challenge popular “pooling” models of crowding. ruth rosenholtz, dian yu, and shaiyan keshvari examine the evidence.
challenges to pooling models of crowding: implications for visual mechanisms



modeling visual crowding

shaiyan keshvari and ruth rosenholtz test a unifying account of visual crowding.



paper accepted to iros 2014

rui and wenzhen’s work on adapting the gelsight sensor for robotic touch has been accepted to iros 2014. this work was done in collaboration with the platt group at neu, and it was covered by mit news.



taking a new look at subway map design


the rosenholtz lab’s texture tiling model was used to evaluate subway maps for the mbta map redesign contest. check out the fastcompany design article, and the csail news article. the news was also picked up by a couple other media sources: smithsonian magazine and the dish. here’s an older article about our research from  science daily.



tactile sensing for manipulation

if robots are to perform everyday tasks in the real world, they will need sophisticated tactile sensing. the tactile data must be integrated into multi-sensory representations that support exploration, manipulation, and other tasks.

tactile sensing for manipulation — (workshop held july 15, 2017)



giving robots a sense of touch

gelsight technology lets robots gauge objects’ hardness and manipulate small tools.

giving robots a sense of touch



fingertip sensor gives robot unprecedented dexterity

armed with the gelsight sensor, a robot can grasp a freely hanging usb cable and plug it into a usb port.

fingertip sensor gives robot unprecedented dexterity



gelsight — portable, super-high-resolution 3-d imaging

a simple new imaging system could help manufacturers inspect their products, forensics experts identify weapons and doctors identify cancers

gelsight — portable, super-high-resolution 3-d imaging



artificial intelligence produces realistic sounds that fool humans

armed with the gelsight sensor, a robot can grasp a freely hanging usb cable and plug it into a usb port.

artificial intelligence produces realistic sounds that fool humans










log in

elmercat 2023


accessibility






