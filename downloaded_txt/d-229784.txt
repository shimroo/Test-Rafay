




















gary king















skip to main content




main menuutility menusearch



harvard.edu 





gary king


bio & c.v.writingsresearch areassoftwaredataverseresearch groupteachingcontactsearch



search 





 











 
 
gary king is the weatherhead university professor at harvard university. he also serves as director of the institute for quantitative social science. he and his research group develop and apply empirical methods in many areas of social science research. full bio and cv
 

 
research areas
methodsanchoring vignettes (for interpersonal incomparability)methods for interpersonal incomparability, when respondents (from different cultures, genders, countries, or ethnic groups) understand survey questions in different ways; for developing theoretical definitions of complicated concepts apparently definable only by example (i.e., "you know it when you see it").automated text analysisautomated and computer-assisted methods of extracting, organizing, understanding, conceptualizing, and consuming knowledge from massive quantities of unstructured text.causal inferencemethods for detecting and reducing model dependence (i.e., when minor model changes produce substantively different inferences) in inferring causal effects and other counterfactuals. matching methods; "politically robust" and cluster-randomized experimental designs; causal bias decompositions.event counts and durationsstatistical models to explain or predict how many events occur for each fixed time period, or the time between events. an application to cabinet dissolution in parliamentary democracies which united two previously warring scholarly literature. other applications to international relations and u.s. supreme court appointments.ecological inferenceinferring individual behavior from group-level data: the first approach to incorporate both unit-level deterministic bounds and cross-unit statistical information, methods for 2x2 and larger tables, bayesian model averaging, applications to elections, software.missing data, measurement error, differential privacystatistical methods to accommodate missing information in data sets due to survey nonresponse, missing variables, or variables measured with error or with error added to protect privacy.  applications and software for analyzing electoral, compositional, survey, time series, and time series cross-sectional data.qualitative researchhow the same unified theory of inference underlies quantitative and qualitative research alike; scientific inference when quantification is difficult or impossible; research design; empirical research in legal scholarship.rare eventshow to save 99% of your data collection costs; bias corrections for logistic regression in estimating probabilities and causal effects in rare events data; estimating base probabilities or any quantity from case-control data; automated coding of events.survey researchhow surveys work and a variety of methods to use with surveys. surveys for estimating death rates, why election polls are so variable when the vote is so predictable, and health inequality.unifying statistical analysisdevelopment of a unified approach to statistical modeling, inference, interpretation, presentation, analysis, and software; integrated with most of the other projects listed here.applicationsevaluating social security forecaststhe accuracy of u.s. social security administration (ssa) demographic and financial forecasts is crucial for the solvency of its trust funds, government programs comprising greater than 50% of all federal government expenditures, industry decision making, and the evidence base of many scholarly articles. forecasts are also essential for scoring policy proposals, put forward by both political parties. because ssa makes public little replication information, and uses ad hoc, qualitative, and antiquated statistical forecasting methods, no one in or out of government has been able to produce fully independent alternative forecasts or policy scorings. yet, no systematic evaluation of ssa forecasts has ever been published by ssa or anyone else. we show that ssa's forecasting errors were approximately unbiased until about 2000, but then began to grow quickly, with increasingly overconfident uncertainty intervals. moreover, the errors all turn out to be in the same potentially dangerous direction, each making the social security trust funds look healthier than they actually are. we also discover the cause of these findings with evidence from a large number of interviews we conducted with participants at every level of the forecasting and policy processes. we show that ssa's forecasting procedures meet all the conditions the modern social-psychology and statistical literatures demonstrate make bias likely. when those conditions mixed with potent new political forces trying to change social security and influence the forecasts, ssa's actuaries hunkered down trying hard to insulate themselves from the intense political pressures. unfortunately, this otherwise laudable resistance to undue influence, along with their ad hoc qualitative forecasting models, led them to also miss important changes in the input data such as retirees living longer lives, and drawing more benefits, than predicted by simple extrapolations. we explain that solving this problem involves using (a) removing human judgment where possible, by using formal statistical methods -- via the revolution in data science and big data; (b) instituting formal structural procedures when human judgment is required -- via the revolution in social psychological research; and (c) requiring transparency and data sharing to catch errors that slip through -- via the revolution in data sharing & replication.an article at barron's about our work.incumbency advantageproof that previously used estimators of electoral incumbency advantage were biased, and a new unbiased estimator. also, the first systematic demonstration that constituency service by legislators increases the incumbency advantage.chinese censorshipwe "reverse engineer" chinese information controls -- the most extensive effort to selectively control human expression in the history of the world. we show that this massive effort to slow the flow of information paradoxically also conveys a great deal about the intentions, goals, and actions of the leaders. we downloaded all chinese social media posts before the government could read and censor them; wrote and posted comments randomly assigned to our categories on hundreds of websites across the country to see experimentally what would be censored; and set up our own social media website in china to observe more closely. we discovered that the chinese government fabricates and posts 450 million social media comments a year in the names of ordinary people. we convinced those fabricating posts (and inadvertently even the government) to admit to these activities. we found that the government does not engage on controversial issues (they do not censor criticism or fabricate posts that argue with those who disagree with them), but they respond on an emergency basis to stop protest and collective action, even if in favor of the government (by censoring, by fabricating posts with giant bursts of cheerleading-type distractions, and by responding to citizen grievances, etc.). they don't care what you think of or say about them; they only care what you can do. and if you have the ability to motivate others to take action, they will try to stop you.mexican health care evaluationan evaluation of the mexican seguro popular program (designed to extend health insurance and regular and preventive medical care, pharmaceuticals, and health facilities to 50 million uninsured mexicans), one of the world's largest health policy reforms of the last two decades. our evaluation features a new design for field experiments that is more robust to the political interventions and implementation errors that have ruined many similar previous efforts; new statistical methods that produce more reliable and efficient results using fewer resources, assumptions, and data, as well as standard errors that are as much as 600% smaller; and an implementation of these methods in the largest randomized health policy experiment to date. (see the harvard gazette story on this project.)presidency research; voting behaviorresolution of the paradox of why polls are so variable over time during presidential campaigns even though the vote outcome is easily predictable before it starts. also, a resolution of a key controversy over absentee ballots during the 2000 presidential election; and the methodology of small-n research on executives.informatics and data sharingreplication standards new standards, protocols, and software for citing, sharing, analyzing, archiving, preserving, distributing, cataloging, translating, disseminating, naming, verifying, and replicating scholarly research data and analyses. also includes proposals to improve the norms of data sharing and replication in science.international conflictmethods for coding, analyzing, and forecasting international conflict and state failure.  evidence that the causes of conflict, theorized to be important but often found to be small or ephemeral, are indeed tiny for the vast majority of dyads, but are large, stable, and replicable wherever the ex ante probability of conflict is large.legislative redistrictingthe definition of partisan symmetry as a standard for fairness in redistricting; methods and software for measuring partisan bias and electoral responsiveness; discussion of u.s. supreme court rulings about this work. evidence that u.s. redistricting reduces bias and increases responsiveness, and that the electoral college is fair; applications to legislatures, primaries, and multiparty systems.mortality studiesmethods for forecasting mortality rates (overall or for time series data cross-classified by age, sex, country, and cause); estimating mortality rates in areas without vital registration; measuring inequality in risk of death; applications to us mortality, the future of the social security, armed conflict, heart failure, and human security.teaching and administrationpublications and other projects designed to improve teaching, learning,
and university administration, as well as broader writings on the future of
the social sciences.
 



recent papers



global maternal health country typologies: a framework to guide policy



zachary j.  ward, rifat  atun, gary  king, brenda  sequeira dmello, and sue j.  goldie. 11/11/2024.  “global maternal health country typologies: a framework to guide policy.” plos global public health, 4, 11, pp. 1-10.abstract articlematernal mortality remains a large challenge in global health. learning from the experience of similar countries can help to accelerate progress. in this analysis we develop a typology of country groupings for maternal health and provide guidance on how policy implications vary by country typology. we used estimates from the global maternal health (gmath) microsimulation model, which was empirically calibrated to a range of fertility, process, and mortality indicators and provides estimates for 200 countries and territories. we used the 2022 estimates of the maternal mortality ratio (mmr) and lifetime risk of maternal death (ltr) and used a k-means clustering algorithm to define groups of countries based on these indicators. we estimated the means of other maternal indicators for each group, as well as the mean impact of different policy interventions. we identified 7 groups (a-g) of country typologies with different salient features. high burden countries (a-b) generally have mmrs above 500 and ltrs above 2%, and account for nearly 25% of global maternal deaths. countries in these groups are estimated to benefit most from improving access to family planning and increasing facility births. middle burden countries (c-e) generally have mmrs between 100–500 and ltrs between 0.5%-3%. countries in these groups account for 55% of global maternal deaths and would benefit most from increasing facility births and improving quality of care. low burden countries (f-g) generally have mmrs below 100 and ltrs below 0.5%, account for 20% of global maternal deaths, and would benefit most from improving access to family planning and community-based interventions and linkages to care. indicators vary widely across groups, but also within groups, highlighting the importance of considering multiple indicators when assessing progress in maternal health. policy impacts also differ by country typology, providing policymakers with information to help prioritize interventions.read more 




automated cognitive debriefing



musashi  hinck, uma  ilavarasan, gary  king, kentaro  nakamura, and brandon m.  stewart. 7/18/2024.  “automated cognitive debriefing.” in society for political methodology. riverside, ca.abstract poster
cognitive debriefing: necessary for researchers & respondents to agree on question meaning but prohibitively expensive, so rarely used.




administer survey, then go back & discuss what respondent thinks each question means.




universally-recommended best practice. 



our goal: easily & drastically improve question wording through an automated cognitive debriefing tool (acd tool). read more 




global maternal mortality projections by urban/rural locationand education level: a simulation-based analysis



zachary j.  ward, rifat  atun, gary  king, brenda  sequeira dmello, and sue j.  goldie. 6/2024.  “global maternal mortality projections by urban/rural locationand education level: a simulation-based analysis.” eclinicalmedicine, 72, pp. 1-12. publisher's versionabstract article
	background


	maternal mortality remains a challenge in global health, with well-known disparities across countries. however, less is known about disparities in maternal health by subgroups within countries. the aim of this study is to estimate maternal health indicators for subgroups of women within each country.


	methods


	in this simulation-based analysis, we used the empirically calibrated global maternal health (gmath) microsimulation model to estimate a range of maternal health indicators by subgroup (urban/rural location and level of education) for 200 countries/territories from 1990 to 2050. education levels were defined as low (less than primary), middle (less than secondary), and high (completed secondary or higher). the model simulates the reproductive lifecycle of each woman, accounting for individual-level factors such as family planning preferences, biological factors (e.g., anemia), and history of maternal complications, and how these factors vary by subgroup. we also estimated the impact of scaling up women's education on projected maternal health outcomes compared to clinical and health system-focused interventions.


	findings


	we find large subgroup differences in maternal health outcomes, with an estimated global maternal mortality ratio (mmr) in 2022 of 292 (95% ui 250–341) for rural women and 100 (95% ui 84–116) for urban women, and 536 (95% ui 450–594), 143 (95% ui 117–174), and 85 (95% ui 67–108) for low, middle, and high education levels, respectively. ensuring all women complete secondary school is associated with a large impact on the projected global mmr in 2030 (97 [95% ui 76–120]) compared to current trends (167 [95% ui 142–188]), with especially large improvements in countries such as afghanistan, chad, madagascar, niger, and yemen.


	interpretation


	substantial subgroup disparities present a challenge for global maternal health and health equity. outcomes are especially poor for rural women with low education, highlighting the need to ensure that policy interventions adequately address barriers to care in rural areas, and the importance of investing in social determinants of health, such as women's education, in addition to health system interventions to improve maternal health for all women.

read more 




statistical intuition without coding (or teachers)



natalie  ayers, gary  king, zagreb  mukerjee, and dominic  skinnion. working paper. “statistical intuition without coding (or teachers)”.abstract papertwo features of quantitative political methodology make teaching and learning especially difficult: (1) each new concept in probability, statistics, and inference builds on all previous (and sometimes all other relevant) concepts; and (2) motivating substantively oriented students, by teaching these abstract theories simultaneously with the practical details of a statistical programming language (such as r), makes learning each subject harder. we address both problems through a new type of automated teaching tool that helps students see the big theoretical picture and all its separate parts at the same time without having to simultaneously learn to program. this tool, which we make available via one click in a web browser, can be used in a traditional methods class, but is also designed to work without instructor supervision. read more 




how american politics ensures electoral accountability in congress



danny  ebanks, jonathan n.  katz, and gary  king. working paper. “how american politics ensures electoral accountability in congress”.abstract paper supplementary appendix
	an essential component of democracy is the ability to hold legislators accountable via the threat of electoral defeat, a concept that has rarely been quantified directly. well known massive changes over time in indirect measures — such as incumbency advantage, electoral margins, partisan bias, partisan advantage, split-ticket voting, and others — all seem to imply wide swings in electoral accountability. in contrast, we show that the (precisely calibrated) probability of defeating incumbent us house members has been surprisingly constant and remarkably high for two-thirds of a century. we resolve this paradox with a generative statistical model of the full vote distribution to avoid biases induced by the common practice of studying only central tendencies, and validate it with extensive out-of-sample tests. we show that different states of the partisan battlefield lead in interestingly different ways to the same high probability of incumbent defeat. many challenges to american democracy remain, but this core feature remains durable. 

read more 




a simulation-based comparative effectiveness analysis of policies to improve global maternal health outcomes



zachary j.  ward, rifat  atun, gary  king, brenda  sequeira dmello, and sue j.  goldie. 4/20/2023.  “a simulation-based comparative effectiveness analysis of policies to improve global maternal health outcomes.” nature medicne. publisher's versionabstract articlethe sustainable development goals include a target to reduce the global maternal mortality ratio (mmr) to less than 70 maternal deaths per 100,000 live births by 2030, with no individual country exceeding 140. however, on current trends the goals are unlikely to be met. we used the empirically calibrated global maternal health microsimulation model, which simulates individual women in 200 countries and territories to evaluate the impact of different interventions and strategies from 2022 to 2030. although individual interventions yielded fairly small reductions in maternal mortality, integrated strategies were more effective. a strategy to simultaneously increase facility births, improve the availability of clinical services and quality of care at facilities, and improve linkages to care would yield a projected global mmr of 72 (95% uncertainty interval (ui) = 58–87) in 2030. a comprehensive strategy adding family planning and community-based interventions would have an even larger impact, with a projected mmr of 58 (95% ui = 46–70). although integrated strategies consisting of multiple interventions will probably be needed to achieve substantial reductions in maternal mortality, the relative priority of different interventions varies by setting. our regional and country-level estimates can help guide priority setting in specific contexts to accelerate improvements in maternal health.read more 




simulation-based estimates and projections of global, regional and country-level maternal mortality by cause, 1990–2050



zachary j.  ward, rifat  atun, gary  king, brenda  sequeira dmello, and sue j.  goldie. 4/20/2023.  “simulation-based estimates and projections of global, regional and country-level maternal mortality by cause, 1990–2050.” nature medicine. publisher's versionabstract articlematernal mortality is a major global health challenge. although progress has been made globally in reducing maternal deaths, measurement remains challenging given the many causes and frequent underreporting of maternal deaths. we developed the global maternal health microsimulation model for women in 200 countries and territories, accounting for individual fertility preferences and clinical histories. demographic, epidemiologic, clinical and health system data were synthesized from multiple sources, including the medical literature, civil registration vital statistics systems and demographic and health survey data. we calibrated the model to empirical data from 1990 to 2015 and assessed the predictive accuracy of our model using indicators from 2016 to 2020. we projected maternal health indicators from 1990 to 2050 for each country and estimate that between 1990 and 2020 annual global maternal deaths declined by over 40% from 587,500 (95% uncertainty intervals (ui) 520,600–714,000) to 337,600 (95% ui 307,900–364,100), and are projected to decrease to 327,400 (95% ui 287,800–360,700) in 2030 and 320,200 (95% ui 267,100–374,600) in 2050. the global maternal mortality ratio is projected to decline to 167 (95% ui 142–188) in 2030, with 58 countries above 140, suggesting that on current trends, maternal mortality sustainable development goal targets are unlikely to be met. building on the development of our structural model, future research can identify context-specific policy interventions that could allow countries to accelerate reductions in maternal deaths.read more 

 1 of 32»all writings

startupspatentssoftware projects
unbiasedprivacyquickcodeopendp: developing open source tools for differential privacyprivacyunbiasedpsi (ψ): a private data sharing interfacecompactness: an r package for measuring legislative district compactness if you only know it when you see itreadme2: an r package for improved automated nonparametric content analysis for social sciencebooc.io: software for an education system with hierarchical concept mapsperusall 1 of 4»all software projects

cluster analysis of participant responses for test generation or teaching (2nd)participant grouping for enhanced interactive experience (4th)instructional support platform for interactive learning platforms (2nd)instructional support platform for interactive learning platformssystem for estimating a distribution of message content categories in source data (2nd)cluster analysis of participant responses for test generation or teachingsystems and methods for keyword determination and document classification from unstructured textparticipant grouping for enhanced interactive experience (3rd)participant grouping for enhanced interactive experience (2nd)stimulating online discussion in interactive learning environmentsall patents



quickcode


perusall


openscholar (acquired by monomyth group)
	

thresher (acquired by two six technologies, a carlyle company; the story)
	

crimson hexagon (merged with brandwatch, acquired by cision; the story)
	

learning catalytics (acquired by pearson; the story)
	


	news story: "entrepreneurial academia with gary king"



 
presentations





            video presentations 

saturday, june 18, 2022

lecture videos for my harvard class ("quantitative social science methods, i", the first course in the graduate sequence at harvard), talks on my research recorded by me, and... read more  about video presentations 
 






            reverse engineering chinese government information controls (university of central florida),         

              at
      
university of central florida,       
wednesday, march 26, 2025:                50c-ucf.pdf

we "reverse engineer" chinese information controls -- the most extensive effort to selectively control human expression in the history of the world. we show that this massive effort to slow the flow of information paradoxically also conveys a great deal about the intentions, goals, and actions of the leaders. we downloaded all chinese social media posts before the government could read and censor them; wrote and posted comments randomly assigned to our categories on hundreds of websites across the country to see experimentally what would be censored; and set up our own ... read more  about reverse engineering chinese government information controls (university of central florida) 
 






            statistically valid inferences from privacy protected data (stat188, harvard university),         

              at
      
harvard university,       
wednesday, november 13, 2024:                udp-stat188.pdf


	venerable procedures for privacy protection and data sharing within academia, companies, and governments, and between sectors, have been proven to be completely inadequate (e.g., respondents in de-identified surveys can usually be re-identified). at the same time, unprecedented quantities of data that could help social scientists understand and ameliorate the challenges of human society are presently locked away inside companies, governments, and other organizations, in part because of worries about privacy violations. we address these problems with a general-... read more  about statistically valid inferences from privacy protected data (stat188, harvard university) 
 






            "reverse engineering" chinese government information controls (suny new paltz),         

              at
      
suny new paltz,       
tuesday, october 15, 2024:                slides


	we "reverse engineer" chinese information controls -- the most extensive effort to selectively control human expression in the history of the world. we show that this massive effort to slow the flow of information paradoxically also conveys a great deal about the intentions, goals, and actions of the leaders. we downloaded all chinese social media posts before the government could read and censor them; wrote and posted comments randomly assigned to our categories on hundreds of websites across the country to see experimentally what would be censored; and set up our own... read more  about "reverse engineering" chinese government information controls (suny new paltz) 
 

 1 of 64»all presentations

books



designing social inquiry: scientific inference in qualitative research, new edition



gary  king, robert o.  keohane, and sidney  verba. 2021. designing social inquiry: scientific inference in qualitative research, new edition. 2nd ed. princeton: princeton university press. publisher's versionabstract
"the classic work on qualitative methods in political science"designing social inquiry presents a unified approach to qualitative and quantitative research in political science, showing how the same logic of inference underlies both. this stimulating book discusses issues related to framing research questions, measuring the accuracy of data and the uncertainty of empirical inferences, discovering causal effects, and getting the most out of qualitative research. it addresses topics such as interpretation and inference, comparative case studies, constructing causal theories, dependent and explanatory variables, the limits of random selection, selection bias, and errors in measurement. the book only uses mathematical notation to clarify concepts, and assumes no prior knowledge of mathematics or statistics.featuring a new preface by robert o. keohane and gary king, this edition makes an influential work available to new generations of qualitative researchers in the social sciences.


	replication data at the harvard dataverse: https://doi.org/10.7910/dvn/yhzg5m.

read more 




the future of political science: 100 perspectives



gary  king, kay  schlozman, and norman  nie. 2009. the future of political science: 100 perspectives. new york: routledge press.read more 




demographic forecasting



federico  girosi and gary  king. 2008. demographic forecasting. princeton: princeton university press.abstract
	we introduce a new framework for forecasting age-sex-country-cause-specific mortality rates that incorporates considerably more information, and thus has the potential to forecast much better, than any existing approach. mortality forecasts are used in a wide variety of academic fields, and for global and national health policy making, medical and pharmaceutical research, and social security and retirement planning.


	as it turns out, the tools we developed in pursuit of this goal also have broader statistical implications, in addition to their use for forecasting mortality or other variables with similar statistical properties. first, our methods make it possible to include different explanatory variables in a time series regression for each cross-section, while still borrowing strength from one regression to improve the estimation of all. second, we show that many existing bayesian (hierarchical and spatial) models with explanatory variables use prior densities that incorrectly formalize prior knowledge. many demographers and public health researchers have fortuitously avoided this problem so prevalent in other fields by using prior knowledge only as an ex post check on empirical results, but this approach excludes considerable information from their models. we show how to incorporate this demographic knowledge into a model in a statistically appropriate way. finally, we develop a set of tools useful for developing models with bayesian priors in the presence of partial prior ignorance. this approach also provides many of the attractive features claimed by the empirical bayes approach, but fully within the standard bayesian theory of inference.


	replication data at the harvard dataverse: https://doi.org/10.7910/dvn/zvn8xq.

read more 




ecological inference: new methodological strategies



gary  king, ori  rosen, martin  tanner, gary  king, ori  rosen, and martin a tanner. 2004. ecological inference: new methodological strategies. new york: cambridge university press.abstract complete bookecological inference: new methodological strategies brings together a diverse group of scholars to survey the latest strategies for solving ecological inference problems in various fields. the last half decade has witnessed an explosion of research in ecological inference – the attempt to infer individual behavior from aggregate data. the uncertainties and the information lost in aggregation make ecological inference one of the most difficult areas of statistical inference, but such inferences are required in many academic fields, as well as by legislatures and the courts in redistricting, by businesses in marketing research, and by governments in policy analysis.read more 




unifying political methodology: the likelihood theory of statistical inference



gary  king. 1998. unifying political methodology: the likelihood theory of statistical inference. ann arbor: university of michigan press. publisher's version errataread more 




a solution to the ecological inference problem: reconstructing individual behavior from aggregate data



gary  king. 1997. a solution to the ecological inference problem: reconstructing individual behavior from aggregate data. princeton: princeton university press. part 1 errata original data (unix) original data (windows)read more 

 1 of 2»all writings
 


an interview with gary

545410ecb22fb17103306f1713325b69

 



video conversations and lectures




lectures for "quantitative social science methods, i"


 
research talks by gary king (recorded by others)
 
research talks by gary king (recorded by me)

 

 
gary king on twitter





@kinggary on twitter
 











 
blogadvice and suggestionsmiscellaneaiq.harvard.edu
 

c05432e852e7f3fbb2c56fc04411b732

 


 


admin login 







copyright © 2025 the president and fellows of harvard college  | accessibility | digital accessibility | report copyright infringement 
















